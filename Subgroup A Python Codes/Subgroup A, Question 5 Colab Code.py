# -*- coding: utf-8 -*-
"""DSA3101 Subgroup A, Question 5

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17PW8iZl2TTRbM7h5Kb7VvBngWpt_LgYM

# Subgroup A, Question 5

## Importing From Google Drive
"""

# Importing From Google Drive
from google.colab import drive
drive.mount('/content/drive')

"""## Importing The Necessary Packages

For this question, we will need to import several packages, inclding pandas for data cleaning and transformation, numpy for numefical computation, matplotlib and seaborn for data visualizations.
"""

# Importing The Necessary Packages

# 1. pandas - to be used for data cleaning
import pandas as pd

# 2. numpy - to be used for numerical computing
import numpy as np

# 3. matplotlib - to be used for data visualizations
import matplotlib.pyplot as plt

# 4. seaborn - to be used for data visualizations
import seaborn as sns

"""## Other Settings Implemented Using Pandas

This is an optional step but the following block of code below helps to change the output structure of the code such that

**1) All the columns of the dataset will be printed**

**2) The width of the dataset output is not limited to the display width of Google Colab**

**3) Prevent wrapping the output to multiple lines on Google Colab to improve readibility**
"""

# Show all columns of the dataset when printed
pd.set_option('display.max_columns', None)

# Don't limit the display width of the output
pd.set_option('display.width', None)

# Don't wrap the output to multiple lines
pd.set_option('display.expand_frame_repr', False)

"""## Reading The Excel File From Google Drive To Google Colab"""

# Specify the file path of the excel file
file_path = '/content/drive/MyDrive/themepark_weather_holiday.csv'

# Read the excel file into Google Colab using read_excel
df = pd.read_csv(file_path)

# Display the first few rows of the dataset
print(df.head())

"""For this question, we will be making use of the `themepark_weather_holiday` dataset, which gives a description of the various weather conditions such as temperature, humidity and precipitation of various Universal Studios of various countries.

Columns Of The Dataset Include:


*   `themepark`: The name of the theme park
*   `country`: The country where the theme park is located
*   `month`: The month for which the data is recorded
*   `avg_crowd_level`: The average crowd level in the theme park for the given month
*   `avg_temp`: The average temperature (in degrees Celsius) during the month
*   `avg_precipitation`: The average precipitation (rainfall) during the month
*   `avg_humidity`: The average humidity percentage for the month
*   `public_holiday`: The number of public holidays in the given month
*   `school_holiday`: The number of school holidays in the given month

--------------------------------------------------------------------------------

### Business Question 5: External Factors And Guest Segmentation

#### Overview Of External Factors And Guest Segmentation In USS:

Understanding the factors that influence visitor trends at Universal Studios Singapore (USS) is essential for effective park management, guest satisfaction, and operational efficiency. Several external factors, such as seasonality, local events, public and school holidays, and weather conditions, play a critical role in determining the segment size of visitors. These fluctuations in crowd levels can directly impact the overall guest experience, from wait times to ride availability and service quality.

One of the primary factors influencing guest segmentation is seasonality. Visitor numbers tend to increase during peak travel seasons, such as summer and year-end holidays when international tourists flock to Singapore. Additionally, local school holidays and long weekends contribute to a surge in domestic visitors. During these peak periods, families and large groups often make up a significant portion of the park's guests, leading to longer wait times and potentially lower satisfaction rates due to overcrowding. Conversely, off-peak months see a different visitor profile, with more adults, young professionals, and international tourists who prefer quieter experiences.

Local events and holidays also play a significant role in shaping visitor segmentation. Major public holidays such as Chinese New Year, National Day, and Deepavali bring a spike in local visitors, while international events like F1 Singapore Grand Prix can influence the influx of tourists. The number of public holidays within a month can directly correlate with crowd levels, as people take advantage of long weekends for leisure activities. Similarly, the number of school holidays within a given period can significantly alter the guest demographic, with more families and younger visitors in attendance.

Additionally, weather conditions contribute to variations in visitor numbers and satisfaction. Rainy months or extreme heat may deter some guests, leading to fluctuating attendance patterns. Visitors tend to be more satisfied during pleasant weather conditions, as it enhances the overall park experience. Unfavorable weather, combined with high crowd levels, can result in lower satisfaction due to ride closures and discomfort.

By analyzing these external factors, USS can better predict visitor segmentation patterns and optimize resource allocation to maintain high satisfaction levels. Implementing crowd control measures, adjusting operational schedules, and enhancing guest services during peak periods can help mitigate the negative impact of external influences on the guest experience.

To tackle this business question, we need to

Step 1: Analyze and explore the `themepark_weather_holiday` dataset, identifying factors that affect the average crowd level of USS.

Step 2: Performing Machine Learning (eg: Linear Regression, Random Forest) to predict average crowd level for various contexts

Step 3: Determining Other Factors That Affect Average Crowd Levels Of USS (Besides Weather)

++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

#### Step 1: Analyze and explore the `themepark_weather_holiday` dataset, identifying factors that affect the average crowd level of USS.

We will delve into various important columns that affect the average crowd level from the columns of the `themepark_weather_holiday` dataset:

Independent Variables:
1.   `avg_temp`: The average temperature (in degrees Celsius) during the month
2.   `avg_precipitation`: The average precipitation (rainfall) during the month
3.   `avg_humidity`: The average humidity percentage for the month
4.   `public_holiday`: The number of public holidays in the given month
5.   `school_holiday`: The number of school holidays in the given month

Dependent Variable:
*   `avg_crowd_level`: The average crowd level in the theme park for the given month

However, before we extract the relevant columns from the dataset, it is important to note to this dataset involves universal studios from various countries (not only Singapore). This results in highly different temperature ranges - for instance some universal studios in Europe has very low temperatures during winter time while other universal studios in tropical climate areas have consistently high temperatures throughout the year.

Without standardizing the temperature, it will lead to inaccuracies in the analysis, as well as the model we will implement later. We first need to standardize the `avg_temp` column.

--------------------------------------------------------------------------------

##### Standardize The Average Temperature Column

The function `standardise_temperature` standardizes the `avg_temp` column using z-score normalization for each country separately. Since different countries have varying temperature ranges, this ensures fair comparison by converting the temperatures into a standardized scale within each country. The function groups the dataset by the country column and applies the transformation:

Z = (X - ùúá) / œÉ

where
X is the original temperature, Œº is the mean temperature for that country, and
œÉ is the standard deviation.

This results in a new column, `standardised_temp`, where values indicate how many standard deviations the original temperature is from the country's mean. The function is then applied to the dataset, modifying it in place.
"""

# Function to standardize the avg_temp column using z-score normalization
def standardise_temperature(df, temp_column="avg_temp", country_column="country"):
    # Apply z-score normalization within each country group
    df["standardised_temp"] = df.groupby(country_column)[temp_column].transform(
        lambda x: (x - x.mean()) / x.std()
    )
    return df

# Apply function to dataset to standardize avg_temp across different countries
df = standardise_temperature(df, temp_column="avg_temp", country_column="country")

# Display the first few rows of the dataframe with the standardized temperatures
print(df.head())

"""We observe that there is the additional column `standardised_temp` that is added to the resulting dataset, having standardized temperature values (Many values are close to 0).

For simplicity, we will not standardize the `avg_precipitation` and `avg_humidity` columns of the datset as location does not affect the amount of precipitation and humidity as much compared to the temperature. Temperature varies significantly between countries due to climate differences, making standardization necessary for fair comparison. However, precipitation and humidity are more influenced by local weather patterns rather than broad geographical differences, so keeping their raw values should still provide meaningful insights.

--------------------------------------------------------------------------------

##### Removing Unnecessary Columns Of The Dataset

There are several unnecessary columns which we do not need to use in our analysis and will later affect our Machine Learning model due to more noise or more features that might lead to overfitting.  

These Columns Are:

1.   `themepark`: The name of the theme park
2.   `country`: The country where the theme park is located
3.   `month`: The month for which the data is recorded
4.   `avg_temp`: The average temperature (in degrees Celsius) during the month

Why These Columns Are Unimportant:

`themepark`  -  This column contains the name of the theme park, but since we are analyzing general trends rather than making park-specific predictions, it does not add much value. Including it in the model could introduce unnecessary complexity and noise. If we were performing park-specific analysis, this column might be useful, but for general crowd and satisfaction trends, it can be removed.

`country` - While country differences may affect temperature and crowd behavior, we have already accounted for this by standardizing temperature within each country. Additionally, other weather-related features like precipitation and humidity are more relevant for predicting attendance patterns. Keeping the country column could lead to overfitting, as the model might memorize country-specific patterns instead of learning general trends.

`month` - The month column may seem relevant because of seasonality, but this information is already indirectly captured by factors like temperature, precipitation, public holidays, and school holidays. Keeping month as a standalone categorical variable could lead to redundant information in the model, increasing complexity without significant predictive power.

`avg_temp` - The column is now irrelavant as we are now using the standardized version of the temperature.

We first remove the first three columns (`themepark`, `country`, and `month`) from the dataset, as they are deemed unnecessary for the analysis. The remaining dataset (`df_corr`) contains only numerical columns relevant to the analysis.
"""

# Create a copy of the original dataset to avoid modifying the original data
df_corr = df.copy()

# Remove the first, second, third, and fifth columns
df_corr = df_corr.drop(df_corr.columns[[0, 1, 2, 4]], axis=1)

# Display the first few rows of the resulting dataframe
print(df_corr.head())

"""--------------------------------------------------------------------------------

##### Generating The Correlation Matrix

The function `plot_cor_matrix` is then defined to create a correlation matrix heatmap using Seaborn's `heatmap()` function. The correlation matrix helps identify relationships between different numerical features by displaying correlation coefficients, with values closer to 1 or -1 indicating strong relationships and values near 0 showing weak or no correlation. The heatmap uses the coolwarm colormap for visualization, and values are displayed with two decimal places. Finally, the function is called to generate and display the heatmap, providing insights into feature relationships in the dataset.
"""

# Function to plot a correlation matrix heatmap
def plot_cor_matrix(df, title="Correlation Matrix for Themepark-Weather-Holiday Data"):
    sns.heatmap(df.corr(), annot=True, cmap="coolwarm", fmt=".2f", linewidths=0.5)
    plt.title(title)
    plt.show()

# Generate and display the correlation matrix heatmap for the cleaned dataset
plot_cor_matrix(df_corr)

"""**Key Insights:**

1. **School Holiday (0.26, Moderate Positive Correlation)**

*   A moderate positive correlation suggests that theme parks tend to be more crowded during school holidays.
*   Possible Reason: Families and students are more likely to visit theme parks when they are not in school, increasing crowd levels.

2. **Standardised Temperature (0.20, Low-Moderate Positive Correlation)**

*   A slightly positive correlation indicates that as temperature increases, the crowd levels also increase to some extent.
*   Possible Reason: Warmer weather is generally more favorable for outdoor activities, making theme parks more attractive. However, extreme heat might deter visitors, which may explain the moderate strength of the correlation.

3. **Public Holiday (-0.07, Negligible Negative Correlation)**

*   The correlation is very weak, suggesting that public holidays do not significantly impact crowd levels.
*   Possible Reason: While some public holidays might see increased visitors, others might not be associated with leisure activities, leading to mixed effects.

4. **Average Humidity (-0.10, Low Negative Correlation)**

*   A weak negative correlation suggests that as humidity rises, crowd levels may slightly decrease.
*   Possible Reason: High humidity can cause discomfort, discouraging visitors from spending extended periods outdoors.

5. **Average Precipitation (-0.01, Almost No Correlation)**

*   There is almost no relationship between precipitation levels and crowd levels.
*   Possible Reason: While extreme rain may deter visitors, mild rain might not significantly impact attendance, leading to an overall neutral correlation.


**Key Takeaways From The Correlation Matrix:**

1.   School holidays have the strongest impact on crowd levels, as families and students visit theme parks during breaks.
2.   Temperature has a moderate effect, with warmer temperatures generally encouraging visits.
3.   Humidity and public holidays have weak negative correlations, suggesting they don't play a major role in crowd fluctuations.

--------------------------------------------------------------------------------

#### Step 2: Performing Machine Learning (eg: Linear Regression, Random Forest) to predict average crowd level for various contexts

**Why Is Machine Learning Important For Enhanced Guest Satisfaction?**

Performing machine learning to predict average crowd levels is a crucial step for optimizing operations, enhancing visitor experience, and improving resource allocation in various contexts, such as theme parks, public events, and tourist attractions.

By leveraging historical data that includes weather conditions, holidays, and other influencing factors, machine learning models can identify complex patterns and trends that may not be immediately apparent through traditional statistical analysis. Accurate crowd predictions enable better decision-making, such as optimizing staff schedules, managing ride wait times, and implementing dynamic pricing strategies.

Additionally, predicting crowd levels helps in enhancing safety measures by preventing overcrowding and ensuring a comfortable visitor experience. For theme park operators, machine learning-driven insights facilitate proactive planning, reducing operational costs while maximizing revenue.

Moreover, visitors can benefit from predictive models through mobile applications or websites that provide real-time forecasts, allowing them to plan their trips accordingly. By integrating machine learning into crowd forecasting, businesses and municipalities can ensure a seamless balance between demand and capacity, leading to an overall improved and efficient service experience.

To predict the average crowd level, we will consider two Machine Learning Models - **Multiple Linear Regression** and **Random Forest**. Before delving into the two Machine Learning models, we will import all the necessary libraries first.
"""

# Import necessary libraries

# Used for feature scaling
from sklearn.preprocessing import StandardScaler

# Splits the dataset into training and testing sets
from sklearn.model_selection import train_test_split

# Implements a linear regression model
from sklearn.linear_model import LinearRegression

# Implements a Random Forest regression model
from sklearn.ensemble import RandomForestRegressor

# Metrics to evaluate model performance
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

"""--------------------------------------------------------------------------------

##### Model 1: Multiple Linear Regression

Multiple Linear Regression (MLR) helps to quantify the relationship between multiple independent variables and a dependent variable, allowing us to understand how different factors collectively influence an outcome.

For instance, in the case of predicting crowd levels, MLR can reveal how variables like temperature, public holidays, school holidays, precipitation, and humidity affect the crowd size.

By analyzing the model's coefficients, we can determine the strength and direction of these relationships ‚Äî whether an increase in temperature or precipitation, for example, leads to a higher or lower crowd level. Additionally, the R-squared value can indicate how much of the variance in crowd levels is explained by these factors.

This understanding allows businesses or event organizers to predict crowd behaviors, optimize resource allocation, and plan better for peak times based on environmental conditions, making MLR a valuable tool for data-driven decision-making.

**Key Benefits Of Using Multiple Linear Rgression Model To Predict Crowd Levels:**

1) **Simplicity and Interpretability**: One of the primary benefits of using a Multiple Linear Regression model is its simplicity and interpretability. Unlike more complex models, MLR allows us to directly understand how each independent variable (such as temperature, holidays, or weather conditions) affects the dependent variable (crowd level) through the coefficients of the model.

2) **Quantifying the Relationship Between Features and Crowd Levels**: In predicting crowd levels at USS, Multiple Linear Regression helps to quantify the relationship between several independent variables (temperature, precipitation, public holidays) and the dependent variable (crowd level). MLR models assume that the relationship between the features and the target is linear. Although the relationship might be complex, MLR gives a straightforward way to calculate the magnitude and direction of the influence each variable has on crowd levels.

3) **Handling Multiple Predictors Simultaneously**: RMLR can handle multiple predictor variables at once, meaning it can account for a variety of factors influencing crowd levels, such as temperature, humidity, holidays, and precipitation, all in one model. For example, a multiple linear regression model could evaluate how temperature and public holidays together affect crowd levels, showing that while temperature alone might increase crowds, the combination of holidays and good weather could have an even larger impact.

4) **Predicting Trends and Making Data-Driven Decisions**: Once trained, the Multiple Linear Regression model can predict future crowd levels based on upcoming weather forecasts, holiday schedules, and other relevant factors. For example, if the model suggests that higher temperatures lead to larger crowds, USS could use weather data to predict when crowds are likely to spike, enabling them to prepare in advance with the right number of staff or additional resources.

5) **Efficiency and Speed**: Multiple Linear Regression is computationally efficient, especially when the dataset is not excessively large. Training the model and making predictions is relatively fast compared to more complex algorithms like Random Forests or Neural Networks. This makes it a good choice for situations where fast, real-time predictions are needed to make decisions, such as predicting crowd levels in advance of the next day or upcoming weekend at USS.

--------------------------------------------------------------------------------

###### Step 1: Define Features and Target Variable

*   The features (`X`) are independent variables that might influence the target.
*   The target (`y`) is what we are trying to predict.

In the context of our weather data, the features are variables such as `standardized_temp`, `avg_precipitation`, `avg_humidity`, `public_holiday` and `school_holiday`.

The target that we are obtaining is `avg_crowd_level`.
"""

# Define features (independent variables) and target (dependent variable)
features = ["standardised_temp", "avg_precipitation", "avg_humidity", "public_holiday", "school_holiday"]
target = "avg_crowd_level"

"""--------------------------------------------------------------------------------

###### Step 2: Split the Data into Training and Testing Sets

The dataset is split into:

*   `X_train`: Training features (80% of data)
*   `X_test`: Testing features (20% of data)
*   `y_train`: Training target values
*   `y_test`: Testing target values

Additionally, `random_state = 42` ensures reproducibility. We will employ the usual 80%-20% train-test-split for our model.
"""

# Split the dataset into training (80%) and testing (20%) subsets
X_train, X_test, y_train, y_test = train_test_split(df_corr[features], df_corr[target],
                                                    test_size=0.2, random_state=42)

"""--------------------------------------------------------------------------------

###### Step 3: Train the Linear Regression Model And Make Predictions

*   `LinearRegression()` initializes the model.
*   `fit(X_train, y_train)` trains the model to learn the relationship between features (`X_train`) and the target variable (`y_train`).
*   The model predicts crowd levels (`y_pred`) using the test dataset.
"""

# Initialize and train the linear regression model
model = LinearRegression()

# Model learns the relationship between X (features) and y (target)
model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test)

"""--------------------------------------------------------------------------------

###### Step 4: Evaluate Model Performance (Using Various Metrics)

We will be evaluating the model performance using several metrics, including Mean Absolute Error, Mean Squared Error and R-Squared.

*   **Mean Absolute Error (MAE)**: Measures the average absolute differences between actual and predicted values.
*   **Mean Squared Error (MSE)**: Similar to MAE but squares errors to penalize larger mistakes more.
*   **R-Squared Score (R¬≤)**: Represents the proportion of variance in the target variable explained by the model (higher is better).
"""

# Evaluate model performance using common regression metrics

# Measures average absolute difference between predictions and actual values
print("Mean Absolute Error:", round(mean_absolute_error(y_test, y_pred), 2))

# Measures average squared difference (penalizes larger errors more)
print("Mean Squared Error:", round(mean_squared_error(y_test, y_pred), 2))

# Indicates how well the model explains variance in the target variable (1 = perfect fit, 0 = no predictive power)
print("R-Squared Score:", round(r2_score(y_test, y_pred), 2))

"""--------------------------------------------------------------------------------

###### Step 5: Display Model Coefficients and Intercept

*   Coefficients (`model.coef_`): Represent how much each feature contributes to the prediction.
*   Intercept (`model.intercept_`): The predicted crowd level when all features are zero.
"""

# Print model coefficients (importance of each feature in predicting the target)
coefficients = model.coef_
intercept = model.intercept_

# Ensure all coefficients and intercept are converted to float and rounded to 2 decimal places
coefficients_rounded = [round(float(coef), 2) for coef in coefficients]
intercept_rounded = round(float(intercept), 2)

print("Model Coefficients:", coefficients_rounded)
print("Model Intercept:", intercept_rounded)

"""--------------------------------------------------------------------------------

##### Model 2: Random Forest

A Random Forest model is a type of ensemble learning algorithm that combines multiple decision trees to make more accurate and robust predictions. It operates on the principle of "many models are better than one," where multiple individual models (decision trees) are trained on random subsets of the data, and their predictions are aggregated (typically by averaging for regression tasks or voting for classification tasks). This approach reduces the risk of overfitting and improves the model's generalization ability compared to a single decision tree, which might be too sensitive to small changes in the training data.

A Random Forest model can be highly effective in predicting crowd levels at Universal Studios Singapore (USS), as it can handle the complex relationships and interactions between various input features. For example, factors like temperature, precipitation, school holidays, public holidays, and humidity all play a role in determining how crowded the theme park might be on a given day. These features can have nonlinear relationships with the target variable (crowd level), and Random Forest is particularly well-suited for capturing such complex patterns.

**Key Benefits Of Using Random Forest Model To Predict Crowd Levels:**

1) **Handling Complex Interactions**: Random Forests can capture interactions between different features (example: temperature and public holidays), which might not be evident in a simple linear model. For instance, the effect of school holidays on crowd levels might vary depending on the temperature, and a Random Forest can model such interactions effectively.

2) **Robustness to Overfitting**: By aggregating multiple decision trees, Random Forest reduces the risk of overfitting. Overfitting happens when a model captures too much noise from the training data, leading to poor performance on new, unseen data. In the case of predicting crowd levels, this would mean that the model could adapt well to changing patterns in crowd behavior without being overly sensitive to fluctuations that might not generalize.

3) **Flexibility with Feature Types**: Random Forests can handle a mix of numerical (example: temperature, humidity) and categorical variables (example: public holidays, school holidays). This allows the model to efficiently learn from diverse data sources, such as weather forecasts or event schedules, to predict crowd levels.

4) **Predicting Nonlinear Relationships**: Unlike linear models that assume a direct relationship between features and target, Random Forest models can account for complex, nonlinear patterns in the data. For example, crowd levels might not increase linearly with temperature but could have thresholds where the relationship changes (example: a slight increase in temperature might drastically increase crowd size after a certain point).

5) **Importance of Features**: Random Forest provides insight into which features (such as temperature, public holidays, or school holidays) are most influential in determining crowd levels. This can help park managers understand what factors drive attendance and enable better decision-making for future planning and resource allocation.

--------------------------------------------------------------------------------

###### Step 1: Define Features and Target Variable

*   The features (`X`) are independent variables that might influence the target.
*   The target (`y`) is what we are trying to predict.

In the context of our weather data, the features are variables such as `standardized_temp`, `avg_precipitation`, `avg_humidity`, `public_holiday` and `school_holiday`.

The target that we are obtaining is `avg_crowd_level`.
"""

# Define features (independent variables) and target (dependent variable)
features = ["standardised_temp", "avg_precipitation", "avg_humidity", "public_holiday", "school_holiday"]
target = "avg_crowd_level"

"""--------------------------------------------------------------------------------

###### Step 2: Split the Data into Training and Testing Sets

The dataset is split into:

*   `X_train`: Training features (80% of data)
*   `X_test`: Testing features (20% of data)
*   `y_train`: Training target values
*   `y_test`: Testing target values

Additionally, `random_state = 42` ensures reproducibility. We will employ the usual 80%-20% train-test-split for our model.
"""

# Split the dataset into training (80%) and testing (20%) subsets
X_train, X_test, y_train, y_test = train_test_split(df_corr[features], df_corr[target],
                                                    test_size=0.2, random_state=42)

"""--------------------------------------------------------------------------------

###### Step 3: Train the Random Forest Model And Make Predictions

*   `RandomForestRegressor()` initializes the random forest model for regression tasks.
*   `n_estimators = 100` specifies that 100 decision trees will be built in the random forest
*   `random_state = 42` ensures reproducibility of the split (same split every time).
*   `fit(X_train, y_train)` trains the model to learn the relationship between features (`X_train`) and the target variable (`y_train`).
*   The model predicts crowd levels (`y_pred`) using the test dataset.
"""

# Initialize the RandomForestRegressor model with 100 trees and a fixed random state for reproducibility
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)

# Train the Random Forest model using the training data (X_train and y_train)
rf_model.fit(X_train, y_train)

# Make predictions on the test set (X_test)
y_pred = rf_model.predict(X_test)

"""--------------------------------------------------------------------------------

###### Step 4: Evaluate Model Performance (Using Various Metrics)

We will be evaluating the model performance using several metrics, including Mean Absolute Error, Mean Squared Error and R-Squared.

*   **Mean Absolute Error (MAE)**: Measures the average absolute differences between actual and predicted values.
*   **Mean Squared Error (MSE)**: Similar to MAE but squares errors to penalize larger mistakes more.
*   **R-Squared Score (R¬≤)**: Represents the proportion of variance in the target variable explained by the model (higher is better).
"""

# Evaluate model performance using common regression metrics

# Measures average absolute difference between predictions and actual values
print("Mean Absolute Error:", round(mean_absolute_error(y_test, y_pred), 2))

# Measures average squared difference (penalizes larger errors more)
print("Mean Squared Error:", round(mean_squared_error(y_test, y_pred), 2))

# Indicates how well the model explains variance in the target variable (1 = perfect fit, 0 = no predictive power)
print("R-Squared Score:", round(r2_score(y_test, y_pred), 2))

"""--------------------------------------------------------------------------------

###### Step 5: Display feature importances

*   `rf_model.feature_importances_` retrieves the importance of each feature in predicting the target variable (crowd level). The higher the importance, the more significant the feature is in making predictions.
*   A new DataFrame is created with two columns: the feature names and their corresponding importance values.
*   `.sort_values(by="Importance", ascending=False)` sorts the features by their importance in descending order, so the most important features come first.
"""

# Extract and display feature importance (how much each feature contributes to the model's predictions)
feature_importance = pd.DataFrame({"Feature": features, "Importance": rf_model.feature_importances_})

# Round the importance values to 2 decimal places
feature_importance["Importance"] = feature_importance["Importance"].round(2)

# Sort by importance in descending order
feature_importance = feature_importance.sort_values(by="Importance", ascending=False)

# Print the feature importance sorted by contribution
print("Feature Importance:")
print()
print(feature_importance)

"""--------------------------------------------------------------------------------

Key Insights:

To determine which model is better (Multiple Linear Regression vs. Random Forest), we can compare the performance of both models across several key metrics: Mean Absolute Error (MAE), Mean Squared Error (MSE) and R-Squared (R¬≤) Score.

<!DOCTYPE html>
  <html lang="en">
  <head>
      <meta charset="UTF-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <style>
          table {
              width: 50%;
              border-collapse: collapse;
              margin: 20px 0;
          }
          th, td {
              border: 1px solid black;
              padding: 10px;
              text-align: center;
          }
      </style>
  </head>
  <body>
      <table>
          <thead>
              <tr>
                  <th>Metric Used</th>
                  <th>Multiple Linear Regression</th>
                  <th>Random Forest</th>
              </tr>
          </thead>
          <tbody>
              <tr>
                  <td>Mean Absolute Error (MAE)</td>
                  <td>10.11</td>
                  <td>8.15</td>
              </tr>
              <tr>
                  <td>Mean Squared Error (MSE)</td>
                  <td>170.96</td>
                  <td>130.16</td>
              </tr>
              <tr>
                  <td>R-Squared (R¬≤)</td>
                  <td>-0.03</td>
                  <td>0.22</td>
              </tr>
      </table>
  </body>
  </html>

1) **Mean Absolute Error (MAE)**

*   Multiple Linear Regression (MLR): 10.11
*   Random Forest (RF): 8.15

The Mean Absolute Error (MAE) measures the average magnitude of errors between the models predictions and the actual values, without considering their direction. A lower MAE indicates better predictive accuracy.

The Random Forest model has a lower MAE (8.15) compared to the Multiple Linear Regression model (10.11), meaning that on average, the Random Forest model's predictions are closer to the actual crowd levels. Therefore, Random Forest performs better in terms of minimizing the average error in prediction.

++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

2) **Mean Squared Error (MSE)**

*   Multiple Linear Regression (MLR): 170.96
*   Random Forest (RF): 130.16

The Mean Squared Error (MSE) penalizes larger errors more than MAE by squaring the differences. Like MAE, a lower MSE indicates better performance.

The Random Forest model has a lower MSE (130.16) than the Multiple Linear Regression model (170.96), indicating that Random Forest tends to produce fewer large errors. This suggests that the Random Forest model is more robust and stable, as it is less sensitive to extreme deviations from the actual crowd levels.

++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

3) **R-Squared Score (R¬≤)**

*   Multiple Linear Regression (MLR): -0.03
*   Random Forest (RF): 0.22

The R-Squared (R¬≤) score measures how well the model explains the variance in the target variable (crowd level). An R¬≤ score closer to 1 indicates a good fit, while negative values indicate that the model is performing worse than a simple mean-based model.

The Multiple Linear Regression model has an R¬≤ score of -0.03, which means it performs worse than a model that simply predicts the mean crowd level for every instance. A negative R¬≤ suggests that the linear relationships between the features and the target are weak or inappropriate for this dataset.

The Random Forest model has a R¬≤ score of 0.22, which while not high, indicates that it explains 22% of the variance in crowd levels. This is a significantly better result than MLR, indicating that Random Forest can capture some of the complex relationships between the features and target.

++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

4) **Feature Importance (Only For Random Forest)**

The Feature Importance values for the Random Forest model show the relative contribution of each feature to the model's predictions:

*  `standardised_temp`: 0.29
*  `avg_humidity`: 0.22
*  `avg_precipitation`: 0.21
*  `school_holiday`: 0.20
*  `public_holiday`: 0.08

Feature importance indicates how much each feature contributes to the model's predictions. Higher values suggest that the feature has a stronger influence.
Temperature (`standardised_temp`) is the most important feature, with an importance of 0.29, meaning it has the largest impact on predicting crowd levels. Humidity and Precipitation are also important, contributing 0.22 and 0.21, respectively. Holidays (school and public holidays) also play a role, but their importance is smaller, with school holidays being more influential than public holidays.

This analysis gives insight into what factors influence crowd levels at USS the most. Random Forest is able to identify the importance of these features and use them accordingly in making predictions.

++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

**Final Conclusion:**

Random Forest appears to be the better model for predicting crowd levels at USS, as it performs better in terms of both predictive accuracy (lower MAE and MSE) and model fit (higher R¬≤ score). It also provides valuable insights into feature importance, helping identify which factors are most influential in determining crowd levels. Multiple Linear Regression, while simpler and more interpretable, fails to capture the complexities of the data, as shown by its poor R¬≤ score and higher error metrics.

--------------------------------------------------------------------------------

#### Step 3: Determining Other Factors That Affect Average Crowd Levels Of USS (Besides Weather)

To determine other factors that affect average crowd levels of USS, we can make use of another dataset that is used in the preceding questions - the cluster dataset that is obtained from Subgroup A, Question 2. We will first import the cluster dataset.
"""

# Specify the file path of the excel file
file_path = '/content/drive/MyDrive/dsa3101_clustered_data.csv'

# Read the excel file into Google Colab using read_excel
df2 = pd.read_csv(file_path)

# Display the first few rows of the dataset
print(df2.head())

"""Here is a description of the what each of the various columns of the cluater dataset represent:

<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <style>
        table {
            width: 50%;
            border-collapse: collapse;
            margin: 20px 0;
        }
        th, td {
            border: 1px solid black;
            padding: 10px;
            text-align: center;
        }
    </style>
</head>
<body>
    <table>
        <thead>
            <tr>
                <th>Column Name</th>
                <th>Description Of Column</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td>cluster</td>
                <td>The cluster the data row is in (Based On Subgroup A, Question 2 Results Obtained)</td>
            </tr>
            <tr>
                <td>q1</td>
                <td>Which type of theme park visitor best describes you?</td>
            </tr>
            <tr>
                <td>q2_1</td>
                <td>What is your age range?</td>
            </tr>
            <tr>
                <td>q2_2</td>
                <td>What is your gender?</td>
            </tr>
            <tr>
                <td>q3</td>
                <td>Are you a tourist or a local?</td>
            </tr>
            <tr>
                <td>q4_1</td>
                <td>For the category on thrill rides, what is the average time you queued for?</td>
            </tr>
            <tr>
                <td>q4_2</td>
                <td>For the category on interactive exhibits, what is the average time you queued for?</td>
            </tr>
            <tr>
                <td>q4_3</td>
                <td>For the category on performances, what is the average time you queued for?</td>
            </tr>
            <tr>
                <td>q4_4</td>
                <td>For the category on food and dining, what is the average time you queued for?</td>
            </tr>
            <tr>
                <td>q5_1</td>
                <td>For the category on thrill rides, what is considered an unacceptable wait time? (Integer in Minutes)</td>
            </tr>
            <tr>
                <td>q5_2</td>
                <td>For the category on interactive exhibits, what is considered an unacceptable wait time? (Integer in Minutes)</td>
            </tr>
            <tr>
                <td>q5_3</td>
                <td>For the category on performances, what is considered an unacceptable wait time? (Integer in Minutes)</td>
            </tr>
            <tr>
                <td>q5_4</td>
                <td>For the category on food and dining, what is considered an unacceptable wait time? (Integer in Minutes)</td>
            </tr>
            <tr>
                <td>q6</td>
                <td>The type of attractions you enjoy the most when visiting USS</td>
            </tr>
            <tr>
                <td>q7</td>
                <td>Factors that will influence your decision to visit a theme park like USS?</td>
            </tr>
            <tr>
                <td>q8</td>
                <td>What type of events influence your decision to visit?</td>
            </tr>
            <tr>
                <td>q9</td>
                <td>How long do you usually spend at USS? (Integer in Hours)</td>
            </tr>
            <tr>
                <td>q10</td>
                <td>When do you usually visit theme parks or attractions like USS?</td>
            </tr>
            <tr>
                <td>q11</td>
                <td>When do you typically purchase meals or snacks at the eateries/restaurants?</td>
            </tr>
            <tr>
                <td>q12</td>
                <td>How do you usually navigate a theme park like USS?</td>
            </tr>
            <tr>
                <td>q13</td>
                <td>Would you be willing to wear a digital watch given by USS to track your location and activity?</td>
            </tr>
            <tr>
                <td>q14_1</td>
                <td>At what time of the day do you usually visit roller coasters?</td>
            </tr>
            <tr>
                <td>q14_2</td>
                <td>At what time of the day do you usually visit water rides?</td>
            </tr>
            <tr>
                <td>q14_3</td>
                <td>At what time of the day do you usually visit 3D/4D experiences?</td>
            </tr>
            <tr>
                <td>q14_4</td>
                <td>At what time of the day do you usually visit performances?</td>
            </tr>
            <tr>
                <td>q14_5</td>
                <td>At what time of the day do you usually visit roadshows?</td>
            </tr>
            <tr>
                <td>q14_6</td>
                <td>At what time of the day do you usually visit eateries and restaurants?</td>
            </tr>
            <tr>
                <td>q14_7</td>
                <td>At what time of the day do you usually visit souvenir shops?</td>
            </tr>
            <tr>
                <td>q14_8</td>
                <td>At what time of the day do you usually visit other rides (carousel rides, teacup rides etc.)?</td>
            </tr>
            <tr>
                <td>q15</td>
                <td>How likely are you to recommend USS to others?</td>
            </tr>
            <tr>
                <td>q16_1</td>
                <td>How satisfied are you with the overall service of the queuing system?</td>
            </tr>
            <tr>
                <td>q16_2</td>
                <td>How satisfied are you with the overall service of retail experience?</td>
            </tr>
            <tr>
                <td>q16_3</td>
                <td>How satisfied are you with the overall service of eateries/restaurants?</td>
            </tr>
            <tr>
                <td>q16_4</td>
                <td>How satisfied are you with the overall service of photo taking exhibitions?</td>
            </tr>
            <tr>
                <td>q16_5</td>
                <td>How satisfied are you with the overall service of entertainment attractions?</td>
            </tr>
            <tr>
                <td>q17_1</td>
                <td>Give an overall rating for ticketing information accessibility</td>
            </tr>
            <tr>
                <td>q17_2</td>
                <td>Give an overall rating for rides and attractions</td>
            </tr>
            <tr>
                <td>q17_3</td>
                <td>Give an overall rating for entertainment and performances</td>
            </tr>
            <tr>
                <td>q17_4</td>
                <td>Give an overall rating for food and beverage</td>
            </tr>
            <tr>
                <td>q17_5</td>
                <td>Give an overall rating for merchandise and shopping</td>
            </tr>
            <tr>
                <td>q17_6</td>
                <td>Provide an overall rating for crowd management, comfort and staff helpfulness</td>
            </tr>
            <tr>
                <td>q18_1</td>
                <td>For ticketing information accessibility, which of the following services are you not satisfied with?</td>
            </tr>
            <tr>
                <td>q18_2</td>
                <td>For rides and attractions, which of the following services are you not satisfied with?</td>
            </tr>
            <tr>
                <td>q18_3</td>
                <td>For entertainment and performances, which of the following services are you not satisfied with?</td>
            </tr>
            <tr>
                <td>q18_4</td>
                <td>For food and beverage, which of the following services are you not satisfied with?</td>
            </tr>
            <tr>
                <td>q18_5</td>
                <td>For merchandise and shopping, which of the following services are you not satisfied with?</td>
            </tr>
            <tr>
                <td>q18_6</td>
                <td>For crowd management, comfort and staff helpfulness, which of the following services are you not satisfied with?</td>
            </tr>
            <tr>
                <td>q19_1</td>
                <td>How important is ticketing information accessibility to your overall satisfaction?</td>
            </tr>
            <tr>
                <td>q19_2</td>
                <td>How important is crowd management to your overall satisfaction?</td>
            </tr>
            <tr>
                <td>q19_3</td>
                <td>How important is staff helpfulness to your overall satisfaction?</td>
            </tr>
            <tr>
                <td>q19_4</td>
                <td>How important is safety and cleanliness to your overall satisfaction?</td>
            </tr>
            <tr>
                <td>q19_5</td>
                <td>How important is rides and attractions to your overall satisfaction?</td>
            </tr>
            <tr>
                <td>q19_6</td>
                <td>How important is food and beverage to your overall satisfaction?</td>
            </tr>
            <tr>
                <td>q19_7</td>
                <td>How important is merchandise and shopping to your overall satisfaction?</td>
            </tr>
            <tr>
                <td>q19_8</td>
                <td>How important is entertainment and performances to your overall satisfaction?</td>
            </tr>
            <tr>
                <td>q20</td>
                <td>Is there any other feedback about your USS experience that you want to mention?</td>
            </tr>
        </tbody>
    </table>
</body>
</html>

--------------------------------------------------------------------------------

##### Extracting The Relevant Columns From The Cluster Dataset

We have identified several columns where we can find several other features besides weather that can affect the average crowd levels of USS (in terms of sensitivity of the customers)

The Columns That Are Relevant Are:

*   `q6`: The type of attractions you enjoy the most when visiting USS
*   `q7`: Factors that will influence your decision to visit a theme park like USS
*   `q8`: The type of events that influence your decision to visit USS
*   `q10`: 	When do you usually visit theme parks or attractions like USS?



However, before we can analyze the customer's sensitivity to the following factors listed in `q6`, `q7` and `q8`, we need to understand about the clusters that we have (cluster 0, cluster 1, cluster 2, ..., cluster 6) as well as figuring out the characteristics of each cluster using certain other columns of the cluster dataset.

The Columns That We Will Explore More Are:

*   `q1`: Which type of theme park visitor best describes you?
*   `q2_1`: What is your age range?
*   `q2_2`: What is your gender?
*   `q3`: Are you a tourist or a local?
*   `q12`: How do you usually navigate a theme park like USS?
"""

# Extracting all the relevant columns for analysis
data = df2[['cluster', 'q1', 'q2_1','q2_2', 'q3', 'q6', 'q7', 'q8', 'q10', 'q12']]

# Drop rows with NaN values in the 'cluster' column
data = data.dropna(subset=['cluster'])

# Convert the 'cluster' column to integers
data['cluster'] = data['cluster'].astype(int)

# Display the first few rows of the dataset with extracted columns
print(data.head())

"""We can count the occurrences of each unique value in the cluster column using `value_counts()`, then sorts the counts in ascending order of the cluster values with `sort_index()`. This allows for a clear display of how many observations are in each cluster, with the results shown in ascending order of the cluster values."""

# Count the occurrences of each unique value in the 'cluster' column
cluster_counts = data['cluster'].value_counts().sort_index()

# Display the count of each cluster value in ascending order
print("Number Of Visitors By Cluster Number:")
print()
print(cluster_counts)

"""--------------------------------------------------------------------------------

##### Create Visualizations To Analyze Demographics Of Each Cluster For Better Understanding Of Guest Segmentation

We will define a function, `plot_bar_per_cluster` that creates a bar chart showing the distribution of responses to a specified survey question (question) across different clusters (`cluster_col`) in the given DataFrame (`df`).

It first extracts the unique cluster values and response labels, excluding `NaN` values. For each cluster, it counts the occurrences of each response to the question, and ensures that all possible response labels are included, filling in missing responses with a count of 0. These response counts for each cluster are stored in a new DataFrame (`plot_data`), with each cluster becoming a new column.

The function then generates a bar plot, displaying the counts of each response for each cluster. This function is useful for visualizing how different clusters respond to a specific question in a survey or dataset.
"""

# Define the function plot_bar_per_cluster
def plot_bar_per_cluster(df, question, cluster_col='cluster', title=None):
    # Get a sorted list of unique cluster values, excluding NaN
    clusters = sorted(df[cluster_col].dropna().unique())

    # Get unique response labels from the specified question column, excluding NaN
    all_labels = df[question].dropna().unique()

    # Create an empty DataFrame to store the count of responses for each cluster
    plot_data = pd.DataFrame(index=all_labels)

    # Loop through each cluster to compute the response distribution for that cluster
    for c in clusters:
        # Get the value counts of responses for the current cluster
        responses = df[df[cluster_col] == c][question].value_counts()

        # Reindex to ensure all possible response labels are included, filling missing labels with 0
        responses = responses.reindex(all_labels, fill_value=0)

        # Add the response counts for the current cluster to the plot_data DataFrame
        plot_data[f'Cluster {c}'] = responses

    # Create a bar plot of the data
    plot_data.plot(kind='bar', figsize=(12, 6))

    # Use the provided title or default title if none is provided
    if title is None:
        title = f"Distribution of '{question}' Responses by Cluster"

    plt.title(title)
    plt.xlabel("Responses")
    plt.ylabel("Count")
    plt.xticks(rotation=45)
    plt.legend(title="Cluster")
    plt.tight_layout()
    plt.show()

"""--------------------------------------------------------------------------------

###### Question 1: Which type of theme park visitor best describes you?
"""

plot_bar_per_cluster(data, 'q1', title="Distribution Of Visitor Type By Cluster")

"""Key Insights:

This graph shows the distribution of visitor types across different clusters at Universal Studios Singapore.

1) Cluster 2 (green) has an extremely high proportion of visitors "Visiting with Friends" compared to other clusters - this appears to be its dominant visitor demographic.

2) Cluster 6 (pink) is strongly characterized by "Family with Young Children" visitors, suggesting this cluster might represent family-friendly attractions or areas.

3) Cluster 4 (purple) has a notable concentration of "Solo Traveller" visitors, distinguishing it from other clusters.

4) "Family with Teenagers" appears relatively evenly distributed across Clusters 0, 3, and 4, suggesting these areas might appeal to families with older children.

5) "Family with Elderly" has the lowest overall visitor count across all clusters, but Cluster 3 (red) shows the highest proportion of this demographic.

6) Clusters 0 (blue) and 3 (red) show more balanced visitor distributions across different types, suggesting these might be areas with broader appeal.

7) Cluster 2's overwhelming popularity with friend groups and Cluster 6's dominance with families with young children indicate clear audience targeting or natural audience preferences for specific areas of the park.

--------------------------------------------------------------------------------

###### Question 2_1: What is your age range?
"""

plot_bar_per_cluster(data, 'q2_1', title="Distribution Of Visitor Age By Cluster")

"""Key Insights:

This graph shows the distribution of visitor ages across different clusters at Universal Studios Singapore.

1) Cluster 2 (green) has an extremely high concentration of visitors aged 21-34, aligning with the previous finding that this cluster attracts primarily friend groups.

2) Cluster 4 (purple) shows strong representation in both the 13-20 age group and the Below 12 years age group, suggesting it appeals to teenagers and younger children.

3) Cluster 6 (pink) has significant numbers of visitors in the Below 12 years category and peaks in the 35-49 years group, matching its earlier identification as appealing to families with young children.

4) Cluster 1 (orange) shows strong presence in the 21-34 age bracket but minimal representation in older age categories, suggesting it appeals to young adults.

5) Cluster 3 (red) has the most balanced distribution across all age groups, including the highest representation in the 65+ category, indicating attractions with broad age appeal.

6) The 21-34 age group has the highest overall visitor count across clusters, making it the park's core demographic.

7) Cluster 0 (blue) maintains moderate representation across all age groups, suggesting attractions that have universal appeal.

8) Older demographics (50-64 and 65+) have lower overall representation across all clusters, with Cluster 3 showing the strongest appeal to these age groups.

--------------------------------------------------------------------------------

###### Question 2_2: What is your gender?
"""

plot_bar_per_cluster(data, 'q2_2', title="Distribution Of Visitor Gender By Cluster")

"""Key Insights:

This graph shows the distribution of visitor gender across different clusters at Universal Studios Singapore.

1) Overall, female visitors outnumber male visitors across most clusters, particularly in Clusters 2, 3, and 4 - where female visitors outnumber males by nearly 2:1.

2) Cluster 3 (red) shows the highest proportion of female visitors and a relatively low proportion of male visitors, suggesting attractions that particularly appeal to women.

3) Cluster 6 (pink) is unique in having more male visitors than female visitors, making it the only male-dominated cluster.

4) Cluster 0 (blue) has a relatively balanced gender distribution, though still with slightly more female visitors.

5) Clusters 2 and 4 (green and purple) both show strong female representation with approximately 52-53 female visitors compared to about 27-30 male visitors.

6) The general female skew across most clusters may indicate that Universal Studios Singapore overall has features or attractions that appeal more strongly to female visitors.

--------------------------------------------------------------------------------

###### Question 3: Are you a tourist or a local?
"""

plot_bar_per_cluster(data, 'q3', title="Distribution Of Visitor Nationality By Cluster")

"""Key Insights:

This graph shows the distribution of visitor nationality (Local vs. Tourist) across different clusters at Universal Studios Singapore.

1) Cluster 0 (blue) is dominated by tourists with approximately 70 tourist visitors and no local visitors, making it exclusively tourist-oriented.

2) Cluster 3 (red) shows the highest number of local visitors (about 82) and no tourists, indicating it strongly appeals to the local Singapore population.

3) Cluster 6 (pink) has a high tourist count (around 65) and no local visitors, making it another tourist-focused area.

4) Cluster 4 (purple) has a more balanced distribution but still skews toward tourists, with about 49 tourists and 34 locals.

5) Clusters 1 and 2 (orange and green) both attract predominantly local visitors (about 48 and 58 respectively) with smaller numbers of tourists (around 19 and 21).

6) Cluster 5 (brown) shows a strong preference among local visitors (around 54) with no tourist representation.

The distinct separation between tourist-exclusive (Clusters 0 and 6) and local-exclusive (Clusters 3 and 5) areas suggests different zones of the park cater to different visitor origins.

--------------------------------------------------------------------------------

###### Question 12: How do you usually navigate a theme park like USS?
"""

plot_bar_per_cluster(data, 'q12', title="Distribution Of Visitor Navigation Preference By Cluster")

"""Key Insights:

This graph shows the distribution of visitor navigation preferences across different clusters at Universal Studios Singapore.

1) "Spontaneous Exploration" is the dominant navigation preference across most clusters, particularly in Cluster 2 (green) which shows the highest count at approximately 53 visitors.

2) Cluster 4 (purple) stands out for having "Following Shortest Queue" as its primary navigation strategy (around 45 visitors), suggesting these visitors prioritize efficiency and minimizing wait times.

3) Cluster 0 (blue) shows a balanced approach with strong representation in both "Spontaneous Exploration" (about 41 visitors) and "Pre-Planned Route" (about 21 visitors).

4) Cluster 6 (pink) has the strongest preference for "Spontaneous Exploration" (around 47 visitors) with much lower counts for other strategies.

5) The "Mix of pre-planning and spontaneous exploration" option is barely represented across all clusters, with only Cluster 2 showing minimal preference for this hybrid approach.

6) Cluster 3 (red) shows relatively balanced preferences between "Spontaneous Exploration" (about 39 visitors) and the other two main strategies.

7) Cluster 5 (brown) visitors strongly prefer "Spontaneous Exploration" (around 32 visitors) with lower numbers for other navigation methods.

--------------------------------------------------------------------------------

##### Identifying Other Factors That Might Affect Average Crowd Levels Due To Changes In Visitor Preferences

To assess the degree to which various factors are prevalent in each cluster, we will visualise their relative frequencies using heatmaps.

To visualize the relative frequencies of various factors across clusters using a heatmap, we can follow these steps:

**1) Compute the frequency of each factor: Calculate the frequency of each unique factor (e.g., responses, features) in each cluster.**

**2) Normalize the data: Convert the frequencies into relative frequencies (e.g., by dividing by the total count of responses in each cluster), so that the values are in the range [0, 1].**

**3) Create a heatmap: Use a heatmap to represent the relative frequencies across clusters, with color intensity indicating the prevalence of each factor.**

The columns that we will be exploring are `q6`, `q7` and `q8` for the different clusters.

The function `plot_multiselect_heatmap` generates a DataFrame containing the relative frequencies of options selected in a multiselect question across different clusters.

It begins by extracting all unique options from the responses in the specified question column and stores them in a sorted list. It then retrieves the unique clusters from the `cluster_col` column and initializes a DataFrame (`heatmap_data`) with clusters as rows and options as columns.

For each cluster, it filters the data, calculates the total number of entries in the cluster, and splits the multiselect responses into individual options. The frequency of each option is counted, and the relative frequency (proportion of the total entries) for each option is computed and stored in the `heatmap_data`. The function returns this DataFrame with the relative frequencies, rounded to two decimal places, allowing for analysis of how frequently each option is selected in each cluster.
"""

def plot_multiselect_heatmap(df, question, cluster_col='cluster', title=None):
    # Step 1: Extract all unique options from the question's responses
    all_options = set()
    df[question].str.split(',').apply(lambda x: all_options.update([i.strip() for i in x]))
    all_options = sorted(all_options)

    # Step 2: Get the sorted unique clusters
    clusters = sorted(df[cluster_col].dropna().unique())

    # Step 3: Create an empty DataFrame to store normalized relative frequencies
    heatmap_data = pd.DataFrame(0.0, index=clusters, columns=all_options, dtype=float)

    # Step 4: Loop through each cluster to compute relative frequencies for each option
    for cluster in clusters:
        cluster_df = df[df[cluster_col] == cluster]
        total = len(cluster_df)

        # Exploding the multiselect answers into individual options
        exploded = cluster_df[question].str.split(',').explode().str.strip()

        # Counting the occurrences of each option in the exploded responses
        option_counts = exploded.value_counts()

        # Step 5: Compute relative frequencies and store in the heatmap data
        for option in all_options:
            # Calculate the relative frequency as a proportion of the total
            relative_freq = (option_counts.get(option, 0) / total) if total > 0 else 0
            heatmap_data.loc[cluster, option] = round(relative_freq, 2)

    # Step 6: Plot the heatmap using seaborn
    plt.figure(figsize=(12, 6))  # Set the size of the heatmap
    sns.heatmap(heatmap_data, annot=True, cmap='Blues', fmt='.2f', cbar=True)

    # Use the provided title or default title if none is provided
    if title is None:
        title = f"Distribution of '{question}' Responses by Cluster"

    # Step 7: Add titles and labels
    plt.title(title)
    plt.xlabel("Options")
    plt.ylabel("Cluster")
    plt.tight_layout()
    plt.show()

"""--------------------------------------------------------------------------------

###### Question 6: The type of attractions you enjoy the most when visiting USS

The function `clean_q6` is designed to clean and standardize responses for the q6 column in the data DataFrame, which contains multiselect options. It first splits the response string by commas to isolate individual options, and then strips any leading or trailing spaces from each option and converts them to title case (e.g., "carousel rides" becomes "Carousel Rides").

The function then iterates through these cleaned options, applying specific corrections: it replaces "Other Rides (Teacup Ride" with "Other rides," skips (does not include) the options "Carousel Rides)" and "Suspended Coasters," and appends the other valid options to the cleaned list.

Finally, the function joins the cleaned options back into a single string separated by commas and returns it. The `data['q6'] = data['q6'].apply(clean_q6)` applies this cleaning function to every entry in the `q6` column of the data DataFrame.
"""

def clean_q6(response):
    # Step 1: Split the response string by commas and strip any extra spaces, then convert to title case
    options = [opt.strip().title() for opt in response.split(',')]
    cleaned = []

    # Step 2: Iterate over each option in the cleaned list
    for opt in options:
        # Step 3: If the option is "Other Rides (Teacup Ride", change it to "Other rides"
        if opt == "Other Rides (Teacup Ride":
            cleaned.append("Other rides")
        # Step 4: If the option is "Carousel Rides)", skip it and don't add it to the cleaned list
        elif opt == "Carousel Rides)":
          continue
        # Step 5: If the option is "Suspended Coasters", skip it and don't add it to the cleaned list
        elif opt == "Suspended Coasters":
          continue
        # Step 6: Otherwise, keep the option as is and add it to the cleaned list
        else:
            cleaned.append(opt)

    # Step 7: Join the cleaned list of options into a single string, separated by commas, and return it
    return ', '.join(cleaned)

# Apply the clean_q6 function to each entry in the 'q6' column of the 'data' DataFrame
data['q6'] = data['q6'].apply(clean_q6)

plot_multiselect_heatmap(data, question='q6', title = "Heatmap Of Most Enjoyable Attractions By Cluster")

"""Key Insights:

This heatmap shows the preference intensity for different attractions across the seven clusters at Universal Studios Singapore.

1) Cluster 2 shows extremely strong preference for Roller Coasters (0.92) and Water Rides (0.71), as well as 3D and 4D Experiences (0.66), aligning with its demographic of 21-34 year-old friend groups.

2) Roller Coasters are particularly popular in Clusters 1 (0.72) and 2 (0.92), but much less appealing to Cluster 6 (0.14), which makes sense given Cluster 6's high proportion of families with young children.

3) Cluster 5 shows the strongest preference for Roadshows (0.56), distinguishing it from other clusters where this attraction type ranks lower.

4) Cluster 6 shows notable preference for Souvenir Shops (0.48), higher than most other clusters, matching its previously identified tourist-heavy demographic.

5) Cluster 4, which had many families with teenagers and children, shows balanced preferences across several attractions, with highest interest in Other rides (0.40) and Roadshows (0.37).

6) Water Rides are highly enjoyed in Clusters 0 (0.43), 1 (0.49), 2 (0.71), and 3 (0.43), but less popular in Clusters 4 and 6 (both 0.20).

7) Eateries and Restaurants receive modest preference ratings across all clusters, with highest appreciation in Cluster 0 (0.39) and Cluster 6 (0.38)

8) Performances show relatively consistent but moderate appeal across all clusters, indicating they're universally appreciated but not the main attraction for any particular group.

--------------------------------------------------------------------------------

###### Question 7: Factors that will influence your decision to visit a theme park like USS

The `clean_q7` function processes and standardizes responses in the `q7` column of the data DataFrame. It begins by splitting each response (a string of multiple options) by commas, trimming any extra spaces, and converting each option to title case.

The function then checks each option and applies specific modifications: it removes the option "Thrill Factor (Not To Be Confused With Scare Factor)," standardizes variations of "Holiday Seasons" and "Weather Conditions" to consistent titles, and appends other valid options without modification.

Finally, the cleaned list of options is joined into a single string with commas separating them, which is returned. The function is applied to the `q7` column using `apply()`, effectively cleaning and standardizing the responses for that column in the dataset.
"""

def clean_q7(response):
    # Step 1: Split the response string by commas, strip extra spaces, and convert to title case
    options = [opt.strip().title() for opt in response.split(',')]
    cleaned = []

    # Step 2: Iterate through each option to clean or modify specific responses
    for opt in options:
        # Step 3: If the option is "Thrill Factor (Not To Be Confused With Scare Factor)", skip it (remove it)
        if opt == "Thrill Factor (Not To Be Confused With Scare Factor)":
            continue
        # Step 4: If the option is "Holiday Seasons" or "Holiday seasons", standardize it to "Holiday Seasons"
        elif opt == "Holiday Seasons" or opt == "Holiday seasons":
            cleaned.append("Holiday Seasons")
        # Step 5: If the option is "Weather Conditions" or "Weather conditions", standardize it to "Weather Condition"
        elif opt == "Weather Conditions" or opt == "Weather conditions":
            cleaned.append("Weather Condition")
        # Step 6: For all other valid options, append them to the cleaned list
        else:
            cleaned.append(opt)

    # Step 7: Join the cleaned list of options into a single string, separated by commas, and return it
    return ', '.join(cleaned)

# Apply the cleaning function to the 'q7' column in the 'data' DataFrame
data['q7'] = data['q7'].apply(clean_q7)

plot_multiselect_heatmap(data, question='q7', title = "Heatmap Of Factors Affecting Decision By Cluster")

"""Key Insights:

This heatmap visualizes factors affecting decisions to visit Universal Studios Singapore across different clusters.  

1) Cluster 2 shows the strongest correlations, particularly with "Cost And Ticket Prices" (0.90), "Weather Condition" (0.84), and "Wait Times For Rides" (0.68). This suggests a highly price-sensitive group that also considers weather and wait times before making decisions.

2) Cluster 1 is moderately influenced by "Weather Condition" (0.61), "Cost And Ticket Prices" (0.63), and "Wait Times For Rides" (0.55), showing similar but less intense priorities than Cluster 2.

3) Clusters 3-6 show generally weaker correlations across all factors, with most values below 0.40, indicating these groups have less strong preferences or are influenced by a more diverse set of factors not fully captured in this analysis.

4) "Special Events" (column 7) strongly influences Clusters 5 and 6 (both at 0.40) compared to other factors for these clusters.

5) "Location And Accessibility" shows the highest value (0.40) for Cluster 6, suggesting this group prioritizes convenience.

--------------------------------------------------------------------------------

###### Question 8: What type of events influence your decision to visit?
"""

plot_multiselect_heatmap(data, question='q8', title = "Heatmap Of Types Of Events By Cluster")

"""Key Insights:

This heatmap displays preferences across different clusters for event types at Universal Studios Singapore

1) Cluster 5 shows the strongest overall preference for visiting USS, particularly for the Minion Land Grand Opening (0.59), followed closely by A Universal Christmas (0.57) and Halloween Horror Night (0.56).

2) Cluster 4 also demonstrates strong interest, especially for Halloween Horror Night (0.58) and both Christmas and Minion Land events (0.55 and 0.54).

3) Clusters 3 and 0 show moderate interest, with particular preference for Minion Land (0.54) and Halloween Horror Night (0.50) in Cluster 3, and Minion Land (0.50) in Cluster 0.

4) Clusters 1, 2, and 6 display lower overall preference, though Cluster 6 shows moderate interest in all events except Universal Christmas.

5) The "None Of The Above" option receives consistently lower scores across most clusters, suggesting these specific events are indeed attractive to visitors.

6) Halloween Horror Night and Minion Land Grand Opening generally receive higher preference scores across clusters than Universal Christmas, indicating these might be more compelling attractions for driving visits.

--------------------------------------------------------------------------------

###### Question 10: When do you usually visit theme parks or attractions like USS?

The code first creates a copy of the original DataFrame data to ensure the original data is preserved. It then processes the `q10` column by splitting each entry at commas and spaces (, ) and expanding the results into multiple rows using the `explode()` function.

A cleaning function, `clean_category`, is applied to standardize and filter the data: it consolidates specific categories like "Special Events (Halloween" into "Special Events" and "Christmas etc.)" into "Christmas", while removing unwanted categories such as "Special Events (Christmas etc.)" and "Weather Conditions".

The function is applied to each entry in the exploded DataFrame, and the resulting `None` values (representing the removed categories) are filtered out, leaving only valid, cleaned categories for further analysis.
"""

# First, create a copy of your original dataframe
df_cleaned = data.copy()

# Step 1: Split the q10 column and explode it into multiple rows
exploded_df = df_cleaned['q10'].str.split(', ').explode()

# Step 2: Clean up and remap the categories
def clean_category(category):
    # Replace "Special Events (Halloween" with "Special Events"
    if "Special Events (Halloween" in category:
        return "Special Events"
    # Replace "Christmas etc.)" with "Christmas"
    elif "Christmas etc.)" in category:
        return "Christmas"
    # Remove the entries "Special Events (Christmas etc.)" and "Weather Conditions"
    elif category in ["Special Events (Christmas etc.)", "Weather Conditions"]:
        return None
    else:
        return category

# Apply the cleaning function
exploded_df = exploded_df.apply(clean_category)

# Step 3: Remove None values (the entries we want to exclude)
exploded_df = exploded_df[exploded_df.notna()]

# Step 4: Reset the index of exploded_df so it matches the original DataFrame
exploded_df = exploded_df.reset_index(drop=True)

# Now, assign the cleaned data back to df_cleaned, creating a new column or adjusting an existing one
df_cleaned['q10'] = exploded_df

plot_multiselect_heatmap(df_cleaned, question='q10', title="Time Of Visitation To USS By Cluster")

"""Key Insights:

This heatmap shows the preferred visitation times to Universal Studios Singapore across different clusters.

Each cluster has distinct visitation preferences:

*  Cluster 0: Prefers weekdays (0.20) and Christmas (0.17)
*  Cluster 1: Strongly favors weekdays (0.21) and school holidays (0.21), with very low interest in public holidays (0.03)
*  Cluster 2: Shows strongest preference for weekdays (0.25)
*  Cluster 3: Has balanced preferences across school holidays, special events, summer festival, and weekdays (all 0.16)
*  Cluster 4: Prefers special events (0.20) and public holidays (0.17)
*  Cluster 5: Strongest preference for school holidays (0.22), with equal interest in weekdays and weekends (0.19)
*  Cluster 6: Favors summer festival (0.22) and Christmas (0.17)

Overall patterns:

*  Weekdays show consistently high preference across most clusters
*  School holidays are popular, particularly with clusters 1 and 5
*  Public holidays generally receive lower preference scores except for cluster 4
*  Summer festival is particularly important to cluster 6
*  Christmas has moderate appeal across several clusters

The strongest preferences in the entire heatmap are:

*  Cluster 2's preference for weekdays (0.25)
*  Cluster 5's preference for school holidays (0.22)
*  Cluster 6's preference for summer festival (0.22)
*  Cluster 1's equal preference for weekdays and school holidays (0.21)

--------------------------------------------------------------------------------

#### Operational Adjustments That Can Be Made During High-Impact Periods

To manage high-impact periods (when there are more visitors) effectively at a tourist destination like Universal Studios Singapore (USS), we can consider implementing the following operational adjustments:

1) **Crowd Management and Visitor Flow Optimization**

*   Timed Entry or Reservation System: Introduce timed entry slots or reservation systems to manage the number of visitors entering the park during peak hours. This can help spread out the crowd and reduce overcrowding.
*   Increase Staff at Critical Points: Deploy additional staff to manage queues at popular attractions, entrances, and food areas, ensuring smooth visitor flow and reducing congestion.
*   Dynamic Pathways or Queuing Systems: Use barriers to create clear pathways or adjust the queuing systems at high-traffic attractions to optimize space and keep visitors moving efficiently.

2) **Optimizing Staffing and Resources**

*   Flexible Staffing Plans: Increase the number of staff during high-impact periods, such as weekends or holidays, to manage crowds effectively, especially at popular attractions, food counters, and guest services.
*   Cross-Training Employees: Ensure staff is cross-trained in various roles so they can step into high-demand areas (such as ticketing or ride assistance) as needed during peak periods.
*   Guest Assistance Zones: Establish dedicated areas where visitors can easily approach staff for information, issues, or guidance during high-traffic times.

3) **Attraction Management**

*  Virtual Queue Systems: Implement virtual queues for high-demand rides or attractions, allowing visitors to reserve a time slot on their phones rather than waiting in long physical lines.
*  Attraction Scheduling: For particularly popular attractions, consider staggered showtimes or timed experiences to reduce bottlenecks at ride entrances.

4) **Crowd Control Through Entertainment**

*  Timed Shows and Performances: Offer more scheduled performances and shows at specific times to distribute crowds evenly across the park, with clear instructions about show timings to avoid congestion.
*  Street Performers and Interactive Events: Deploy roaming entertainers or interactive experiences in areas where visitors typically gather, helping disperse crowds and maintaining engagement.

5) **Park Infrastructure and Facilities Management**

*  Optimize Restroom and Dining Areas: Increase the number of open dining areas and restrooms during peak hours to prevent overcrowding and improve comfort.
*  Additional Merchandise and Food Stalls: Add temporary food stands or mobile food trucks in areas with high foot traffic to reduce long lines at regular dining spots. Also, ensure there are adequate merchandise booths around the park.

--------------------------------------------------------------------------------
"""