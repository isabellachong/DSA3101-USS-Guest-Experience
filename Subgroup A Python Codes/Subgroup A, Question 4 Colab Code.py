# -*- coding: utf-8 -*-
"""DSA3101 Group Project (Group 3, Subgroup A, Question 4)

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CTQgJJ3dJQmwRsrum9mjqzmCXqG40fS8

# Subgroup A, Question 4

## Importing From Google Drive
"""

# Importing From Google Drive
from google.colab import drive
drive.mount('/content/drive')

"""## Importing The Necessary Packages"""

# Importing The Necessary Packages

# 1. pandas - to be used for data cleaning
import pandas as pd

# 2. numpy - to be used for numerical computing
import numpy as np

# 3. matplotlib - to be used for data visualizations
import matplotlib.pyplot as plt

# 4. seaborn - to be used for data visualizations
import seaborn as sns

# 5. sklearn - to be used for Machine Learning implementation
import sklearn

"""## Other Settings Implemented Using Pandas

This is an optional step but the following block of code below helps to change the output structure of the code such that

**1) All the columns of the dataset will be printed**

**2) The width of the dataset output is not limited to the display width of Google Colab**

**3) Prevent wrapping the output to multiple lines on Google Colab to improve readibility**
"""

# Show all columns of the dataset when printed
pd.set_option('display.max_columns', None)

# Don't limit the display width of the output
pd.set_option('display.width', None)

# Don't wrap the output to multiple lines
pd.set_option('display.expand_frame_repr', False)

"""## Reading The Excel File From Google Drive To Google Colab"""

# Specify the file path of the excel file
file_path = '/content/drive/MyDrive/uss_survey_responses.xlsx'

# Read the excel file into Google Colab using read_excel
df = pd.read_excel(file_path)

# Display the first few rows of the dataset
print(df.head())

"""## Examining The Number Of Rows And Columns Of The Dataset

We can examine the number of rows and columns of the dataset using `df.shape`, where the first number represents the number of rows and the second number represents the number of columns of the dataset.
"""

# Finding the number of rows and columns of the dataset
num_rows, num_columns = df.shape

# Displaying the results
print("Number of Rows:", num_rows)
print("Number of Columns:", num_columns)

"""We observe that there are 505 rows and 56 columns in the dataset.
The columns include the email address of the survey responders, as well as their responses to the 20 questions in the survey (some of the survey questions have various subparts, hence more than 20 columns altogether). We currently have 505 survey responses in our dataset.

Since the email address is considered highly confidential, in order to maintain data integrity to prevent exposure of information and privacy leaks, we should remove the `email address` column. Also, the `time_entry` column is not really important in our analysis as this column just represents when the respondants have completed the survey (within a period of a few days, all recent entries). We can also remove the column.
"""

# Removing the email addressand time_entry column of the dataset
df = df.drop('Email Address', axis = 1)
df = df.drop('time_entry', axis = 1)

# Displaying the first few rows of the updated dataset
print(df.head())

"""## What Each Column Of The Dataset Represent (From The Survey Questions)

Here is a description of the what each of the various columns of the dataset represent:

<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <style>
        table {
            width: 50%;
            border-collapse: collapse;
            margin: 20px 0;
        }
        th, td {
            border: 1px solid black;
            padding: 10px;
            text-align: center;
        }
    </style>
</head>
<body>
    <table>
        <thead>
            <tr>
                <th>Column Name</th>
                <th>Description Of Column</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td>q1</td>
                <td>Which type of theme park visitor best describes you?</td>
            </tr>
            <tr>
                <td>q2_1</td>
                <td>What is your age range?</td>
            </tr>
            <tr>
                <td>q2_2</td>
                <td>What is your gender?</td>
            </tr>
            <tr>
                <td>q3</td>
                <td>Are you a tourist or a local?</td>
            </tr>
            <tr>
                <td>q4_1</td>
                <td>For the category on thrill rides, what is the average time you queued for?</td>
            </tr>
            <tr>
                <td>q4_2</td>
                <td>For the category on interactive exhibits, what is the average time you queued for?</td>
            </tr>
            <tr>
                <td>q4_3</td>
                <td>For the category on performances, what is the average time you queued for?</td>
            </tr>
            <tr>
                <td>q4_4</td>
                <td>For the category on food and dining, what is the average time you queued for?</td>
            </tr>
            <tr>
                <td>q5_1</td>
                <td>For the category on thrill rides, what is considered an unacceptable wait time? (Integer in Minutes)</td>
            </tr>
            <tr>
                <td>q5_2</td>
                <td>For the category on interactive exhibits, what is considered an unacceptable wait time? (Integer in Minutes)</td>
            </tr>
            <tr>
                <td>q5_3</td>
                <td>For the category on performances, what is considered an unacceptable wait time? (Integer in Minutes)</td>
            </tr>
            <tr>
                <td>q5_4</td>
                <td>For the category on food and dining, what is considered an unacceptable wait time? (Integer in Minutes)</td>
            </tr>
            <tr>
                <td>q6</td>
                <td>The type of attractions you enjoy the most when visiting USS</td>
            </tr>
            <tr>
                <td>q7</td>
                <td>Factors that will influence your decision to visit a theme park like USS?</td>
            </tr>
            <tr>
                <td>q8</td>
                <td>What type of events influence your decision to visit?</td>
            </tr>
            <tr>
                <td>q9</td>
                <td>How long do you usually spend at USS? (Integer in Hours)</td>
            </tr>
            <tr>
                <td>q10</td>
                <td>When do you usually visit theme parks or attractions like USS?</td>
            </tr>
            <tr>
                <td>q11</td>
                <td>When do you typically purchase meals or snacks at the eateries/restaurants?</td>
            </tr>
            <tr>
                <td>q12</td>
                <td>How do you usually navigate a theme park like USS?</td>
            </tr>
            <tr>
                <td>q13</td>
                <td>Would you be willing to wear a digital watch given by USS to track your location and activity?</td>
            </tr>
            <tr>
                <td>q14_1</td>
                <td>At what time of the day do you usually visit roller coasters?</td>
            </tr>
            <tr>
                <td>q14_2</td>
                <td>At what time of the day do you usually visit water rides?</td>
            </tr>
            <tr>
                <td>q14_3</td>
                <td>At what time of the day do you usually visit 3D/4D experiences?</td>
            </tr>
            <tr>
                <td>q14_4</td>
                <td>At what time of the day do you usually visit performances?</td>
            </tr>
            <tr>
                <td>q14_5</td>
                <td>At what time of the day do you usually visit roadshows?</td>
            </tr>
            <tr>
                <td>q14_6</td>
                <td>At what time of the day do you usually visit eateries and restaurants?</td>
            </tr>
            <tr>
                <td>q14_7</td>
                <td>At what time of the day do you usually visit souvenir shops?</td>
            </tr>
            <tr>
                <td>q14_8</td>
                <td>At what time of the day do you usually visit other rides (carousel rides, teacup rides etc.)?</td>
            </tr>
            <tr>
                <td>q15</td>
                <td>How likely are you to recommend USS to others?</td>
            </tr>
            <tr>
                <td>q16_1</td>
                <td>How satisfied are you with the overall service of the queuing system?</td>
            </tr>
            <tr>
                <td>q16_2</td>
                <td>How satisfied are you with the overall service of retail experience?</td>
            </tr>
            <tr>
                <td>q16_3</td>
                <td>How satisfied are you with the overall service of eateries/restaurants?</td>
            </tr>
            <tr>
                <td>q16_4</td>
                <td>How satisfied are you with the overall service of photo taking exhibitions?</td>
            </tr>
            <tr>
                <td>q16_5</td>
                <td>How satisfied are you with the overall service of entertainment attractions?</td>
            </tr>
            <tr>
                <td>q17_1</td>
                <td>Give an overall rating for ticketing information accessibility</td>
            </tr>
            <tr>
                <td>q17_2</td>
                <td>Give an overall rating for rides and attractions</td>
            </tr>
            <tr>
                <td>q17_3</td>
                <td>Give an overall rating for entertainment and performances</td>
            </tr>
            <tr>
                <td>q17_4</td>
                <td>Give an overall rating for food and beverage</td>
            </tr>
            <tr>
                <td>q17_5</td>
                <td>Give an overall rating for merchandise and shopping</td>
            </tr>
            <tr>
                <td>q17_6</td>
                <td>Provide an overall rating for crowd management, comfort and staff helpfulness</td>
            </tr>
            <tr>
                <td>q18_1</td>
                <td>For ticketing information accessibility, which of the following services are you not satisfied with?</td>
            </tr>
            <tr>
                <td>q18_2</td>
                <td>For rides and attractions, which of the following services are you not satisfied with?</td>
            </tr>
            <tr>
                <td>q18_3</td>
                <td>For entertainment and performances, which of the following services are you not satisfied with?</td>
            </tr>
            <tr>
                <td>q18_4</td>
                <td>For food and beverage, which of the following services are you not satisfied with?</td>
            </tr>
            <tr>
                <td>q18_5</td>
                <td>For merchandise and shopping, which of the following services are you not satisfied with?</td>
            </tr>
            <tr>
                <td>q18_6</td>
                <td>For crowd management, comfort and staff helpfulness, which of the following services are you not satisfied with?</td>
            </tr>
            <tr>
                <td>q19_1</td>
                <td>How important is ticketing information accessibility to your overall satisfaction?</td>
            </tr>
            <tr>
                <td>q19_2</td>
                <td>How important is crowd management to your overall satisfaction?</td>
            </tr>
            <tr>
                <td>q19_3</td>
                <td>How important is staff helpfulness to your overall satisfaction?</td>
            </tr>
            <tr>
                <td>q19_4</td>
                <td>How important is safety and cleanliness to your overall satisfaction?</td>
            </tr>
            <tr>
                <td>q19_5</td>
                <td>How important is rides and attractions to your overall satisfaction?</td>
            </tr>
            <tr>
                <td>q19_6</td>
                <td>How important is food and beverage to your overall satisfaction?</td>
            </tr>
            <tr>
                <td>q19_7</td>
                <td>How important is merchandise and shopping to your overall satisfaction?</td>
            </tr>
            <tr>
                <td>q19_8</td>
                <td>How important is entertainment and performances to your overall satisfaction?</td>
            </tr>
            <tr>
                <td>q20</td>
                <td>Is there any other feedback about your USS experience that you want to mention?</td>
            </tr>
        </tbody>
    </table>
</body>
</html>

****************************************************************************************************************************************************************

### Business Question 4: Impact Of Marketing Strategies On Guest Behaviour

#### Overview Of Using Marketing Strategies:

To assess the impact of marketing strategies on guest behavior, it is essential to first identify the characteristics of customers who spend at Universal Studios Singapore (USS). Tailoring marketing efforts to underrepresented groups without considering the broader customer base may limit their effectiveness in enhancing the overall guest experience. This, in turn, could result in minimal or no significant increase in demand for USS, potentially restricting revenue growth and preventing the park from maximizing its financial performance.

However, merely identifying customer characteristics is not sufficient to develop effective marketing strategies. It is equally important to analyze shifts in customer trends over time—for example, observing a consistent increase in the percentage of visitors aged 13 to 21. By tracking these evolving patterns, USS can better predict future customer demographics and tailor its marketing efforts accordingly.

Focusing on growing customer segments allows USS to implement targeted strategies that align with emerging trends, maximizing demand and ensuring sustained business growth. By comparing past demographic data with current visitor profiles, we can assess percentage changes across different customer segments. This analysis enables USS to better understand evolving visitor trends and develop targeted strategies to align with shifting consumer behaviors.

We need to analyze past campaign data to study changes in guest segment size and satisfaction. To identify trends and analyze shifts in customer patterns, it is essential to utilize historical demographic data from visitors to Universal Studios Singapore (USS), ideally from 10 or more years ago. This long-term dataset provides a more accurate basis for trend analysis, minimizing short-term fluctuations and errors.

To tackle this business question, we need to

Step 1: From the current survey dataset, we will obtain and analyze the demographics of visitors, including age range, visitor type, gender, salary range as well as time of visitations and special occasions

Step 2: Similar to Step 1, we will obtain and analyze the the demographics of visitors who visited USS some time ago

Step 3: We will then compare the demographics of current visitors versus visitors several years ago using some visualizations + identify some noticeable increasing trends, as well as the majority classes

Step 4: We will implement effective strategies to tailor to these large groups of people to increase user experience and ultimately increase revenue/profits for USS

++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

#### Step 1: Obtain And Analyze The Demographics Of Current Visitors In USS

From the current survey dataset that we have obtained, we can categorize the guest types based on several factors listed below:

*   **Visitor Demographics - Age, Gender, Nationality (Tourist/Local)**
*   **Visitor Type - Solo Travellor/Visiting With Friends/Family/Children etc.**
*   **Time Of Day - Weekdays/Weekends/Public Holidays etc.**
*   **Special Events - Halloween/Christmas etc.**

We will explore each bullet point one by one. We will first start with the Visitor Demographics.

--------------------------------------------------------------------------------

##### Visitor Demographics

For the point on Visitor Demographics, there are several features that we can explore. These include:

*   **Age Of Visitors**
*   **Gender Of Visitors**
*   **Nationality Of Visitors (Tourists/Local)**

###### Age Of Visitors

First, for the age of visitors, we split the visitors ages into various categories, such as

1.   Below 12 years old (Children)
1.   13 to 20 years old (Teenagers)
3.   21 to 34 years old (Young Adults)
4.   35 to 49 years old (Mid-Career Adults)
5.   50 to 64 years old (Mature Adults)
6.   65 years old and above (Seniors)

We can plot the number of each type of visitors using a bar chart, categrorized by age group. The column that we will be focusing on is `q2_1` (What is your age range?)
"""

# Extract q2 (Age Range Column)
df_agerange = df['q2_1']

# Define the desired order of age categories
order = ["Below 12 Years Old", "13 To 20 Years Old", "21 To 34 Years Old",
         "35 To 49 Years Old", "50 To 64 Years Old", "65 Years Old And Above"]

# Count occurrences and reindex to match the desired order
person_type_counts = df_agerange.value_counts().reindex(order, fill_value=0)

# Convert index to categorical with specified order
person_type_counts.index = pd.Categorical(person_type_counts.index, categories=order, ordered=True)

# Create a bar plot
plt.figure(figsize=(10, 6))
ax = sns.barplot(x=person_type_counts.index, y=person_type_counts.values, order=order, color="skyblue")

# Add title and labels
plt.title('Number Of Respondents Based On Age Range (Current Data)')
plt.xlabel('Age Range Categories')
plt.ylabel('Number of Respondents')

# Rotate x-axis labels for better readability
plt.xticks(rotation=30, ha='right')

# Add grid lines for better readability
plt.grid(axis='y', linestyle='--', alpha=0.3)

# Add number labels on top of bars
for i, value in enumerate(person_type_counts.values):
    ax.text(i, value + 1, str(value), ha='center', va='bottom', fontsize=10)

# Show the plot
plt.show()

"""Key Observations And Insights:

1) The age range category that has the highest number of respondants is 21 To 34 Years Old (Young Adults). This is followed by 13 To 20 Years Old (Teenagers) and Below 12 Years Old (Children).

2) The number of respondants aged 34 years and below contributes to the majority of the total number of survey responses, almost 75% of the total number of respondants are in this age range.

3) From 35 years old onwards, the bar graph shows a continuous decline in the number of respondants. The lowest number of respondants turned out to be 65 years old and above (Elderly).

We will analyse the age range categories further using heatmaps further in Step 3 when we are interested in comparing the proportions of respondants with particular age ranges over time.

--------------------------------------------------------------------------------

###### Gender Of Visitors

We can plot the proportion of gender of visitors using a pie chart. The column that we will be focusing on is `q2_2` (What is your gender?)

***NOTE: For simplicity, we only assume two possible genders - Male and Female. We have made this question a mandatory question for the survey respondants to answer and give them only two options to choose from. We have explained to the respondants on the main page that their information will be kept confidential and will not be exposed to the public or on any websites. The information will only be used for data analysis and insights.***
"""

# Extract gender column
df_gender = df['q2_2']

# Count the number of Male and Female in dataset
gender_counts = df_gender.value_counts()

# Define colors: Blue for Male, Pink for Female
colors = ['#ff69b4', '#377eb8']

# Create a pie chart
plt.figure(figsize = (9, 9))
plt.pie(gender_counts, labels = gender_counts.index, autopct = '%1.1f%%',
        colors = colors, startangle = 90, wedgeprops = {'edgecolor': 'black'})

# Add title
plt.title('Proportion of Male and Female Participants (Current Data)')

# Add legend
plt.legend(title = "Gender", loc = "best")

# Show the plot
plt.show()

"""The pie chart reveals that 61% of respondents are female, while the remaining 39% are male. This indicates that the majority of visitors to Universal Studios Singapore (USS) are female. However, to determine whether this trend is a recent development or a long-standing pattern, it is essential to compare these proportions with historical data. Analyzing past visitor demographics will help assess any shifts in gender distribution over time.

--------------------------------------------------------------------------------

###### Nationality Of Visitors

We can similarly plot the proportion of Nationality of visitors using a pie chart. The column that we will be focusing on is `q3` (Are you a tourist or a local?)

***NOTE: For simplicity, we only assume two possible answers - tourist or local. This is because if we ask the tourists further on which country that they are from, there will be a myriad of different answers as there are over 200 countries in the world. This might result in too many categories for us to analyze and given the limited number of survey responses that we have collected, some countries might only have 1 or 2 responses which cannot be used to compare differences subsequently in Step 3***
"""

# Extract nationality column
df_nationality = df['q3']

# Count the number of Locals and Tourists in dataset
nationality_counts = df_nationality.value_counts()

# Define colors: Salmon Red for Local, Pastel Blue for Tourist
colors = ['#FA8072', '#AEC6CF']

# Create a pie chart
plt.figure(figsize = (9, 9))
plt.pie(nationality_counts, labels = nationality_counts.index, autopct = '%1.1f%%',
        colors = colors, startangle = 90, wedgeprops = {'edgecolor': 'black'})

# Add title
plt.title('Proportion of Locals And Tourists (Current Data)')

# Add legend
plt.legend(title = "Nationality Type", loc = "best")

# Show the plot
plt.show()

"""The pie chart reveals that 55.2% of respondents are locals, while the remaining 44.8% are tourists. This indicates that the majority of visitors to Universal Studios Singapore (USS) are locals. This might at first seem a little concerning as despite the small population size of Singapore (only around 6 million compared to billions in the world), it still accounts for the majority of visitor count to USS. We need to explore further as to why there might be insufficient tourists in USS.

However, to determine whether this trend is a recent development or a long-standing pattern, it is essential to compare these proportions with historical data. Analyzing past visitor demographics will help assess any shifts in nationality distribution over time.

--------------------------------------------------------------------------------

##### Visitor Type

The types of visitors can be categorized as follows:

*   Solo Traveller
*   Visiting with Friends
*   Families with Young Children
*   Families with Teenagers
*   Families with Elderly

To visualize the distribution of the above visitor types, we will plot a bar chart using column `q1` of the `uss_survey_responses.xlxs` dataset. (Which type of theme park visitor best describes you?)
"""

# Specify order
order = ['Solo Traveller', 'Visiting With Friends', 'Family With Young Children',
         'Family With Teenagers', 'Family With Elderly']

# Create a bar plot
plt.figure(figsize=(10, 6))
ax = sns.countplot(x='q1', data=df, order=order, color="lightblue")

# Add title and labels
plt.title('Number Of Respondents Based On Visitor Type')
plt.xlabel('Visitor Categories')
plt.ylabel('Number of Respondents')

# Rotate x-axis labels for better readability
plt.xticks(rotation=30, ha='right')

# Add grid lines for better readability
plt.grid(axis='y', linestyle='--', alpha=0.3)

# Add number labels on top of bars
for p in ax.patches:
    ax.annotate(f'{int(p.get_height())}',
                (p.get_x() + p.get_width() / 2., p.get_height()),
                ha='center', va='bottom', fontsize=10)

# Show the plot
plt.show()

"""Based on our survey responses, we can see that the largest group of visitors are families with young children. Guests who visit with friends form the next largest group, followed by familiy with teenagers. Solo travellers also form a sizeable group, making up 19% of the total survey respondants. Analyzing past visitor types will help us explore how the distribution of visitor types have shifted over time.

--------------------------------------------------------------------------------

##### Time Of Day

For the feature on the Time Of Day, we can break down into two categories:

**1st Category: When do visitors usually spend their day at USS?**

**2nd Category: What time of the day constitutes the highest demand?**

###### Category 1:

For the first category of "When do visitors usually spend their day at USS?", we can make use of column `q10` (When do you usually visit theme parks or attractions like USS?). This question targets the day type aspect of visitation. We can make use of a bar graph to plot the number of responses who select the possible options below.

The Possible Options Include:

*   Weekdays
*   Weekends
*   Public Holidays
*   School Holidays
*   Special Events (Halloween, Summer Festival, Christmas)
*   Other Inputs By User (Can Be Anything)



However, users are allowed to select multiple options from the list above and hence, we cannot plot the bar graph immediately. We need to perform some data cleaning and manipulation first before visualizing.

First, we need to identify all the unique categories of `q10` as some users might have inputted their preferred days under the "Other Inputs By User" section of the survey question.
"""

# Replace "Special Events (...)" with "Special Events" using regex
q10_column = df['q10'].replace(r'Special Events \(.*\)', 'Special Events', regex=True)

# Merge all values in q10_column into a list
q10_list = q10_column.tolist()

# Flatten the list by splitting each entry by commas and then flattening it
flattened_list = [item.strip() for sublist in q10_list for item in sublist.split(',')]

# Find unique categories
unique_categories = set(flattened_list)
print(unique_categories)

"""We observe that there are other entries such as 'When I feel like it' and '1 day in 25 years' that are in the resulting set of unique values, but are not available in the fixed options in the survey.

Data Cleaning Process:

1) Extract the `q10` column of the dataset

2) Separate the options using the comma delimiter for entries with more than 1 option

3) Performing One-Hot Encoding to create new columns - `weekdays`, `weekends`, `public_holidays`, `school_holidays` and `special_events` and others in the set containing 0 for absence and 1 for presence

4) Count the total number of 1's for each column of the 7 new columns created
"""

# Step 1: Extract the q10 column from the dataset
q10_column = df['q10']

# Replace "Special Events (...)" with "Special Events" using regex
q10_column = q10_column.replace(r'Special Events \(.*\)', 'Special Events', regex=True)

# Step 2: Separate the options using the comma delimiter for entries with more than 1 option
# We will split the entries and expand them into separate rows and then get the unique values
split_q10 = q10_column.str.split(',', expand=True)

# Step 3: Perform One-Hot Encoding
# Define the categories we want to create columns for
categories = ['Weekdays', 'Weekends', 'Public Holidays',
              'School Holidays', 'Special Events', 'When I feel like it',
              '1 day in 25 years']

# Create a new dataframe with columns for each category
one_hot_df = pd.DataFrame(0, index = df.index, columns = categories)

# Step 4: Fill the new columns with 1s where the category is present
for category in categories:
    one_hot_df[category] = split_q10.apply(lambda row: 1 if category in row.values else 0, axis = 1)

# Step 5: Count the total number of 1's for each new column created
count_ones = one_hot_df.sum()

# Display the result
print("Total Count Of Preferred Day Of Visitation:\n")
print(count_ones)

"""We can see that there are 7 unique categories, but two of them - "When I feel like it" and "1 day in 25 years" contain only one response, so we will exclude these two categories. We will proceed to plot a bar chart showcasing the total count for the remaining 5 categories having considerable number of responses."""

# Remove the "When I feel like it" and "1 day in 25 years" categories
count_ones = count_ones.drop(['When I feel like it', '1 day in 25 years'])

# Sort the count_ones in descending order
count_ones = count_ones.sort_values(ascending = False)

# Plot the bar chart with a color
plt.figure(figsize = (10, 8))
ax = count_ones.plot(kind = 'bar', color = "skyblue")

# Add labels and title
plt.title('Total Count of Preferred Day of Visitation (Current Data)')
plt.xlabel('Day Type')
plt.ylabel('Number Of Respondants')
plt.xticks(rotation = 45, ha = 'right')

# Step 7: Add number labels on top of the bars
for i in range(len(count_ones)):
    ax.text(i, count_ones.iloc[i] + 2, str(count_ones.iloc[i]), ha = 'center',
            va = 'bottom', fontsize = 10)

# Show the plot
plt.show()

"""Key Observations And Insights:

1) Weekdays have the largest number of respondants (138), indicating that the majority of visitors might choose a weekday to visit USS. There might be several reasons such as avoiding large crowds on weekends and public holidays or that there might be certain promotions or discounts given on weekdays that entice customers to visit USS on a weekday instead.

2) School Holidays also contribute to a significant number of responses (108) probably because there are many school children and teenagers who are only able to visit USS in this period due to their school/work days.

3) Special Events account for the lowest number of respondants (77). This might be attributed to the fact that there are only some special events held in USS and some visitors might have visited other entertainment venues (not USS) in these occasions.

--------------------------------------------------------------------------------

###### Category 2:

For the second category of "What time of the day constitutes the highest demand?", we can make use of several columns of the dataset to answer the question. This question targets the time aspect of visitation.

The columns that we will consider include:

*   `q14_1`: At what time of the day do you usually visit roller coasters?
*   `q14_2`: At what time of the day do you usually visit water rides?
*   `q14_3`:	At what time of the day do you usually visit 3D/4D experiences?
*   `q14_4`:	At what time of the day do you usually visit performances?
*   `q14_5`:	At what time of the day do you usually visit roadshows?
*   `q14_6`:	At what time of the day do you usually visit eateries and restaurants?
*   `q14_7`:	At what time of the day do you usually visit souvenir shops?
*   `q14_8`:	At what time of the day do you usually visit other rides (carousel rides, teacup rides etc.)?


**However, these columns selected target the popular times for each attraction, which we are not focusing on for this business question. We are instead focusing on the most popular timings in USS in general (not specific to each attraction). Instead, we should modify the columns above such that we calculate the combined count of each time category for all the eight columns.**

We can make use of another bar graph to plot the number of responses who select the possible options below.

The Possible Options Include:

*   Early Morning (8am to 10am)
*   Late Morning (10am to 12pm)
*   Early Afternoon (12pm to 2pm)
*   Late Afternoon (2pm to 4pm)
*   Evening (4pm to 6pm)
*   Night (6pm to 9pm)
*   I Do Not Visit

For these questions, users are not allowed to select any other option or type other suitable timings. Hence, there are only six categories that we will consider.
"""

# Extract the relevant columns for time ranges
popular_time_range = df[['q14_1', 'q14_2', 'q14_3', 'q14_4', 'q14_5', 'q14_6', 'q14_7', 'q14_8']]

# Flatten the DataFrame and split entries with commas into separate values
flattened_time_range = popular_time_range.values.flatten()

# Split by commas for entries with multiple options
split_time_range = [item.strip() for sublist in flattened_time_range for item in str(sublist).split(',')]

# Convert to a pandas Series for easier counting
time_range_series = pd.Series(split_time_range)

# Count the occurrences of each time slot
time_slot_counts = time_range_series.value_counts()

# Display the results
print("Combined Total Count for Each Time Slot:")
print(time_slot_counts)

"""From the result count obtained, we can see that the data is not clean and there are several entries that do not fit into the seven given categories. The improper results include 10 null values, 3 "i Do Not Visit" entries where the letter i is in small letter and a "Lunch (11am to 2pm)" entry with the wrong time period.

We need to process this further by:

1) Removing all the incorrect entries

2) All the number of "i Do Not Visit" entries, which is 3, to the "I Do Not Visit" entry
"""

# Remove invalid entries
time_slot_counts = time_slot_counts[~time_slot_counts.index.isin(['', 'Lunch (11am to 2pm)', 'i Do Not Visit'])]

# Add 3 to the count of "I Do Not Visit"
time_slot_counts = time_slot_counts.rename(index = {'i Do Not Visit': 'I Do Not Visit'})
time_slot_counts['I Do Not Visit'] += 3

# Display the cleaned results
print("Cleaned Combined Total Count for Each Time Slot:\n")
print(time_slot_counts)

"""The result is now cleaned and correct and we can proceed to plot the bar graph. We will order the bars of the graph by the time of the day - Leftmost bar represents Early Morning (8am to 10am) and the rightmost bar represents Night (6pm to 9pm). Also, we will exclude the I Do Not Visit entries as we are only interested in the visitation timings of USS.

**NOTE: The y-axis values of the bars do not truly reflect the actual number of respondants who visited USS due to the manipulation of the column values, as well as it is not possible for a certain visitor to be in multiple attractions at one time. There might be certain inaccuracies. Instead, we will just note the trend of the bars over time from early morning to night and observe which bars are the longest/shortest.**
"""

# Remove the "I Do Not Visit" category for plotting
time_slot_counts = time_slot_counts.drop(['I Do Not Visit'])

# Define the desired order of time categories
order = ["Early Morning (8am to 10am)", "Late Morning (10am to 12pm)",
         "Early Afternoon (12pm to 2pm)", "Late Afternoon (2pm to 4pm)",
         "Evening (4pm to 6pm)", "Night (6pm to 9pm)"]

# Reindex the time_slot_counts to ensure the desired order
time_period_counts = time_slot_counts.reindex(order, fill_value=0)

# Convert index to categorical with specified order
time_period_counts.index = pd.Categorical(time_period_counts.index,
                                          categories = order, ordered = True)

# Create a bar plot
plt.figure(figsize = (10, 8))
ax = sns.barplot(x = time_period_counts.index, y = time_period_counts.values,
                 order = order)

# Add title and labels
plt.title('Number Of Visitations Based On Time Periods (Current Data)')
plt.xlabel('Time Periods')
plt.ylabel('Number of Respondents')

# Rotate x-axis labels for better readability
plt.xticks(rotation = 30, ha = 'right')

# Add grid lines for better readability
plt.grid(axis = 'y', linestyle = '--', alpha = 0.3)

# Add number labels on top of bars
for i, value in enumerate(time_period_counts.values):
    ax.text(i, value + 1, str(value), ha='center', va='bottom', fontsize=10)

# Show the plot
plt.show()

"""Key Observations And Insights:

1) We observe that based on the length of the bars, Late Afternoon (2pm to 4pm) is the period of time where USS is the most crowded and has the most number of visitors. This is followed by Evening (4pm to 6pm) and Early Afternoon (12pm to 2pm). We can conclude that the peak times of USS span from Midday to around 6pm in the evening.

2) The least popular timing is Early Morning (8am to 10am) when USS just opens and might be still too early for some individuals who might be asleep at this timing. Demand is not as high. Night (6pm to 9pm) also has a lower number of respondants as it might be too late for some individuals possibly due to the fact that they might have work/school the next day.

--------------------------------------------------------------------------------

##### Special Events

To investigate the impact of special events on visitors, we will first analyze column `q7` (What are the factors that will influence your decision to visit a theme park like USS?) to see if `Special Events` is an important factor to survey respondants.

`q7` consists of the following options, where survey respondants are allowed to choose several options:

*   Weather Conditions
*   Holiday Seasons
*   Wait Times For Rides
*   Attraction Variety
*   **Special Events**
*   Cost And Ticket Prices
*   Location And Accessibility
*   Reputation And Reviews
*   Safety And Cleanliness
*   Other inputs by respondants

First, we will identify the unique categories of `q7` using the `.unique()` method
"""

# Merge all values in q7_column into a list
q7_column = df['q7']
q7_list = q7_column.tolist()

# Flatten the list by splitting each entry by commas and then flattening it
flattened_list = [item.strip() for sublist in q7_list for item in sublist.split(',')]

# Find unique categories
unique_categories = set(flattened_list)
print(unique_categories)

"""We observe that there are other entries such as `Whether I am working or not!` and `Thrill factor (not to be confused with scare factor` that are in the resulting set of unique values, but are not available in the fixed options in the survey.

Data Cleaning Process:

1) Extract the `q7` column of the dataset

2) Replace all `Holiday seasons` with `Holiday Seasons` and replace all `Weather conditions` with `Weather Conditions`

3) Separate the options using the comma delimiter for entries with more than 1 option

4) Performing One-Hot Encoding to create new columns containing 0 for absence and 1 for presence

5) Count the total number of 1's for each of the new columns created
"""

# Step 1: Extract the q7 column from the dataset
q7_column = df['q7']

# Step 2: Replace "Holiday seasons" with "Holiday Seasons" and "Weather conditions" with "Weather Conditions"
q7_column = q7_column.replace({'Holiday seasons': 'Holiday Seasons',
                               'Weather conditions': 'Weather Conditions'})

# Step 3: Separate the options using the comma delimiter for entries with more than 1 option
# We will split the entries and expand them into separate rows and then get the unique values
split_q7 = q7_column.str.split(',', expand=True).apply(lambda x: x.str.strip())

# Step 4: Perform One-Hot Encoding
# Define the categories we want to create columns for
categories = ['Weather Conditions', 'Holiday Seasons', 'Wait Times For Rides',
              'Attraction Variety', 'Special Events', 'Cost And Ticket Prices',
              'Location And Accessibility', 'Reputation And Reviews',
              'Safety And Cleanliness', 'Whether I am working or not!',
              'Aesthetics', 'Thrill factor (not to be confused with scare factor)']

# Create a new dataframe with columns for each category
one_hot_df = pd.DataFrame(0, index = df.index, columns = categories)

#Fill the new columns with 1s where the category is present
for category in categories:
    one_hot_df[category] = split_q7.apply(lambda row: 1 if category in row.values else 0, axis = 1)

# Step 5: Count the total number of 1's for each new column created
count_ones = one_hot_df.sum()

# Display the result
print("Total Count Of Factors Affecting Visitation:\n")
print(count_ones)

"""We observe that there are several entries such as "Whether I am working or not!", "Aesthetics" and "Thrill Factor" there have only a count of 1 and can be excluded from the analysis. Excluding the 3 factors with a count of 1, we will now plot a bar chart for the remaining columns."""

# Remove the categories with count = 1
count_ones = count_ones.drop(['Whether I am working or not!', 'Aesthetics',
                              'Thrill factor (not to be confused with scare factor)'])

# Sort the count_ones in descending order
count_ones = count_ones.sort_values(ascending = False)

print(count_ones)

# Define bar colors: magenta for "Special Events", blue for others
colors = ['magenta' if index == "Special Events" else 'blue' for index in count_ones.index]

# Create the bar plot with customized colors
plt.figure(figsize=(12, 8))
ax = count_ones.plot(kind='bar', color=colors)

# Add labels and title
plt.title('Total Count of Each Factor Influencing Theme Park Visitation')
plt.xlabel('Factors')
plt.ylabel('Number of Respondents')
plt.xticks(rotation=45, ha='right')

# Add number labels on top of the bars
for i in range(len(count_ones)):
    ax.text(i, count_ones.iloc[i] + 2, str(count_ones.iloc[i]), ha='center',
            va='bottom', fontsize=10)

# Add grid lines for better readability
plt.grid(axis='y', linestyle='--', alpha=0.3)

# Show the plot
plt.show()

"""The bar chart above suggests that `Special Events` may not be as important as other factors such as `Cost And Ticket Prices` and `Weather Conditions` in influencing survey respondants to visit theme parks. However, it is still a factor taken into consideration by 29% of respondants.

To further investigate which particular special events attract visitors, we will analyse column `q8` (What type of events influence your decision to visit?), which consists of the following options:

*   **Minion Land Grand Opening**
*   **Halloween Horror Night**
*   **A Universal Christmas**
*   **None Of The Above**

Since respondants are allowed to choose several options, we will perform One-Hot Encoding, then use a bar chart to visualize the total count for each option.
"""

# Step 1: Extract the q7 column from the dataset
q8_column = df['q8']

# Step 2: Separate the options using the comma delimiter for entries with more than 1 option
# We will split the entries and expand them into separate rows and then get the unique values
split_q8 = q8_column.str.split(',', expand=True).apply(lambda x: x.str.strip())

# Step 3: Perform One-Hot Encoding
# Define the categories we want to create columns for
categories = ['Minion Land Grand Opening',
              'Halloween Horror Night',
              'A Universal Christmas',
              'None Of The Above']

# Create a new dataframe with columns for each category
one_hot_df = pd.DataFrame(0, index = df.index, columns = categories)

#Fill the new columns with 1s where the category is present
for category in categories:
    one_hot_df[category] = split_q8.apply(lambda row: 1 if category in row.values else 0, axis = 1)

# Step 4: Count the total number of 1's for each new column created
count_ones = one_hot_df.sum()

# Display the result
print("Total Count Of Factors Affecting Visitation:\n")
print(count_ones)

# Sort the count_ones in descending order
count_ones = count_ones.sort_values(ascending = False)

# Plot the bar chart with a color
plt.figure(figsize = (12, 8))
ax = count_ones.plot(kind = 'bar')

# Add labels and title
plt.title('Total Count of Events Attracting Visitors')
plt.xlabel('Events')
plt.ylabel('Number Of Respondents')
plt.xticks(rotation = 45, ha = 'right')

# Add number labels on top of the bars
for i in range(len(count_ones)):
    ax.text(i, count_ones.iloc[i] + 2, str(count_ones.iloc[i]), ha = 'center',
            va = 'bottom', fontsize = 10)

# Add grid lines for better readability
plt.grid(axis='y', linestyle='--', alpha=0.3)

# Show the plot
plt.show()

"""Key Observations And Insights:

From the bar chart above, we observe that `Halloween Horror Night` is most likely to attract guests to visit USS, followed by `Minion Land Grand Opening` then `A Universal Christmas`, but the difference in total count between the 3 events is not large. However, we have to note that `Minion Land Grand Opening` is a one-time event while `Halloween Horror Night` and `A Universal Christmas` are annual events.

--------------------------------------------------------------------------------

##### Satisfaction Ratings
"""



"""++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

#### Step 2: Obtain And Analyze The Demographics Of Visitors Who Visited USS Some Time Ago

After analyzing the demographics of current visitors to Universal Studios Singapore (USS), we will now extend our analysis to past visitors.

To achieve this, we will utilize a survey dataset from Kaggle, which contains visitor data for various Universal Studios locations worldwide from 2010 to 2021 (spanning approximately 4 to 14 years ago). The dataset is made by combining all the reviews on Trip Advisor for the various Universal Studios around the world. This dataset will serve as our historical reference for examining visitor demographics and satisfaction scores. However, before proceeding with the analysis, we must first clean and preprocess the data to ensure accuracy and reliability.
"""

# Specify the file path of the excel file
file_path_two = '/content/drive/MyDrive/uss_historical_reviews.xlsx'

# Read the excel file into Google Colab using read_excel
df_history = pd.read_excel(file_path_two)

# Display the first few rows of the dataset
print(df_history.head())

"""The dataset contains 12 columns:

1. `reviewer` - The name of the reviewer (might not be real name)
2. `Gender` - The gender of the reviewer
3. `Age Range` - The age range of the reviewer
4. `Tourist or Local` - Whether the reviewer is a tourist or a local
5. `branch` - The Universal Studios branch the reviewer went
6. `time_of_day` - The time the reviewer prefers to go to USS
7. `visitor_type` - Who does the visitor go with (Family, Friends, Alone etc.)
8. `day_preferred` - What day does the reviewer prefer to go to USS
9. `written-date` - The time when the reviewer wrote the review
10. `rating` - The rating the reviewer gave to his/her Universal Studios Experience
11. `title` - The title the reviewer wrote on Trip Advisor
12. `review_text` - The review description that the reviewer gave on Trip Advisor

Let us examine the dataset more:

We can first find the total number of rows of the dataset using the `shape` method.
"""

# Determining the number of rows and columns of the dataset
print("Shape Of The Historical Dataset\n")
print(df_history.shape)

"""The dataset contains 50904 rows.

Next, we will examine the unique values of several of the categorical columns of the dataset to check for any anomaly values. These categorical columns include the branch (`branch`), the age range (`Age Range`), the gender (`Gender`), the nationality (`Tourist or Local`), the preferred day (`day_preferred`), the time preferred (`time_of_day`) and the visitor type (`visitor_type`).


"""

# Unique Values For Branch Column
print("Unique Values For Branch Column:")
print(df_history['branch'].unique())
print()

# Unique Values For Age Range Column
print("Unique Values For Age Range Column:")
print(df_history['Age Range'].unique())
print()

# Unique Values For Gender Column
print("Unique Values For Gender Column:")
print(df_history['Gender'].unique())
print()

# Unique Values For Nationality Column
print("Unique Values For Nationality Column:")
print(df_history['Tourist or Local'].unique())
print()

# Unique Values For Preferred Day
print("Unique Values For Preferred Day Column:")
print(df_history['day_preferred'].unique())
print()

# Unique Values For Time Of Day
print("Unique Values For Time Of Day Column:")
print(df_history['time_of_day'].unique())
print()

# Unique Values Fpr Visitor Type
print("Unique Values For Visitor Type Column:")
print(df_history['visitor_type'].unique())

"""We observe that that there are indeed no anomalies in these columns of the dataset. There are three branches available in the dataset - Universal Studios Florida, Universal Studios Japan and Universal Studios Singapore. For the other columns of the historical dataset, it tallies with the columns of our current survey dataset, so no additonal cleaning to remove anomalies is required for this portion.

To clean the raw dataset from Kaggle, we need to do the following:

*   Remove Unnecessary Columns - `reviewer`, `title`, `review_text` and `written_date`
*   Filter The Dataset For Rows Where `branch` is "Universal Studios Singapore" as we are not interested in other Universal Studios.
*   Rename Column Names For Consistency (`Gender` to `gender`, `Tourist or Local` to `nationality`, `Age Range` to `age_range`)
*   Rearrange The Columns Of The Dataset Where The Order Is - `gender`, `age_range`, `nationality`, `branch`, `visitor_type`, `day_preferred`, `time_of_day`, `rating`)
"""

# Remove unnecessary columns
df_history = df_history.drop(columns=['reviewer', 'title', 'review_text',
                                      'written_date'])

# Filter for rows where 'branch' is "Universal Studios Singapore"
df_history = df_history[df_history['branch'] == "Universal Studios Singapore"]

# Rename columns for consistency
df_history = df_history.rename(columns={
    'Gender': 'gender',
    'Tourist or Local': 'nationality',
    'Age Range': 'age_range'
})

# Rearrange the columns in the specified order
df_history = df_history[['gender', 'age_range', 'nationality', 'branch',
                         'visitor_type', 'day_preferred', 'time_of_day', 'rating']]

# Reset the index and start from 1 instead of 0
df_history = df_history.reset_index(drop=True)
df_history.index += 1

# Display the first few rows
print(df_history.head())

# Determining the number of rows and columns of the cleaned dataset
print("Shape Of The Cleaned Historical Dataset\n")
print(df_history.shape)

"""We observe that the number of columns of the dataset is reduced to 8 - which tallies with the columns of `gender`, `age_range`, `nationality`, `branch`, `visitor_type`, `day_preferred`, `time_of_day` and `rating`. The number of rows has also been reduced significantly from 50904 rows to 15754 rows due to the fact that we only kept rows containing survey responses from Universal Studios Singapore. This also agrees with the fact that the original dataset contains only about 35% of reviews from Universal Studios Singapore.

Using this cleaned dataset, we can now proceed to analyze the demographics and satisfaction rates of customers who visited USS some time ago.

##### Visitor Demographics

###### Age Of Visitors:
"""

# Extract the age_range column
dfhistory_agerange = df_history['age_range']

# Define the desired order of age categories
order = ["Below 12 Years Old", "13 To 20 Years Old", "21 To 34 Years Old",
         "35 To 49 Years Old", "50 To 64 Years Old", "65 Years Old And Above"]

# Count occurrences and reindex to match the desired order
ages = dfhistory_agerange.value_counts().reindex(order, fill_value=0)

# Convert index to categorical with specified order
person_type_counts.index = pd.Categorical(ages.index, categories=order, ordered=True)

# Create a bar plot
plt.figure(figsize=(10, 6))
ax = sns.barplot(x=ages.index, y=ages.values, order=order)

# Add title and labels
plt.title('Number Of Respondants Based On Age Range (Historical Data)')
plt.xlabel('Age Range Categories')
plt.ylabel('Number of Respondents')

# Rotate x-axis labels for better readability
plt.xticks(rotation=30, ha='right')

# Add grid lines for better readability
plt.grid(axis='y', linestyle='--', alpha=0.3)

# Add number labels on top of bars
for i, value in enumerate(ages.values):
    ax.text(i, value + 1, str(value), ha='center', va='bottom', fontsize=10)

# Show the plot
plt.show()

"""Key Observations And Insights:

1) We observe that contrary to the current visitor dataset where 21 to 34 years old (Young Adults) forms the majority of the survey responses, the historical visitor data reveals that the majority of visitors are in the age range of 13 to 20 years old (Teenagers).

2) The age range of 21 to 34 years old still form a significant proportion of the visitors in the historical data. The downward trend from the category of 21 to 34 years old to 65 years old ad above is similar to that of the current survey data.

3) The age group that has the lowest number of respondants is still 65 years and above, similar to the current survey data.

--------------------------------------------------------------------------------

###### Gender Of Visitors:
"""

# Extract gender column
dfhistory_gender = df_history['gender']

# Count the number of Male and Female in dataset
gender_counts_h = dfhistory_gender.value_counts()

# Define colors: Blue for Male, Pink for Female
colors = ['#377eb8', '#ff69b4']
#377eb8
# Create a pie chart
plt.figure(figsize = (9, 9))
plt.pie(gender_counts_h, labels = gender_counts_h.index, autopct = '%1.1f%%',
        colors = colors, startangle = 90, wedgeprops = {'edgecolor': 'black'})

# Add title
plt.title('Proportion of Male and Female Participants (Historical Data)')

# Add legend
plt.legend(title = "Gender", loc = "best")

# Show the plot
plt.show()

"""Key Observations Ans Insights:

Contrary to the current visitor survey responses where Females make up the majority of data, for the historical visitor survey responses, Male (67.7%) makes up most of the data as compared to Female (32.3%).

This shows that over time, there might either be:

**1) More Females interested in visiting USS**

**2) Less Males interested in visiting USS**

**3) Both (1) and (2)**

We will discuss more about this in Steps 3 and 4 of the question.

--------------------------------------------------------------------------------

###### Nationality Of Visitors
"""

# Extract nationality column
dfhistory_nationality = df_history['nationality']

# Count the number of Locals and Tourists in dataset
nationality_counts_h = dfhistory_nationality.value_counts()

# Define colors: Salmon Red for Local, Pastel Blue for Tourist
colors = ['#AEC6CF', '#FA8072']
#FA8072
# Create a pie chart
plt.figure(figsize = (9, 9))
plt.pie(nationality_counts_h, labels = nationality_counts_h.index, autopct = '%1.1f%%',
        colors = colors, startangle = 90, wedgeprops = {'edgecolor': 'black'})

# Add title
plt.title('Proportion of Locals And Tourists (Historical Data)')

# Add legend
plt.legend(title = "Nationality Type", loc = "best")

# Show the plot
plt.show()

"""Key Observations Ans Insights:

Contrary to the current visitor survey responses where Locals make up the majority of data, for the historical visitor survey responses, Tourists (65.7%) makes up most of the data as compared to Locals (34.3%).

This shows that over time, there might either be:

**1) More Locals interested in visiting USS**

**2) Less Tourists interested in visiting USS**

**3) Both (1) and (2)**

We will discuss more about this in Steps 3 and 4 of the question.

--------------------------------------------------------------------------------

##### Visitor Type

We will use the `visitor_type` column of the historical dataset to explore the distribution of visitor types in the past.
"""

# Specify order
order = ['Solo Traveller', 'Visiting With Friends', 'Families With Young Children',
         'Families With Teenagers', 'Families With Elderly']

# Create a bar plot
plt.figure(figsize=(10, 6))
ax = sns.countplot(x='visitor_type', data=df_history, order=order, color="lightblue")

# Add title and labels
plt.title('Number Of Reviewers Based On Visitor Type (Historical Data)')
plt.xlabel('Visitor Categories')
plt.ylabel('Number of Reviewers')

# Rotate x-axis labels for better readability
plt.xticks(rotation=30, ha='right')

# Add grid lines for better readability
plt.grid(axis='y', linestyle='--', alpha=0.3)

# Add number labels on top of bars
for p in ax.patches:
    ax.annotate(f'{int(p.get_height())}',
                (p.get_x() + p.get_width() / 2., p.get_height()),
                ha='center', va='bottom', fontsize=10)

# Show the plot
plt.show()

"""From the above bar chart, we observe that there is a significantly higher proportion of visitors who are `Families With Young Children`, as compared to the survey responses where the difference in proportion was not as significant. Another observation is that there is a higher proportion of `Families With Elderly` as compared to `Solo Travellers` and `Families With Teenagers`, which differs from our earlier analysis based on recent survey responses.

These differences could be explained by possible reasons below:

**1) Distributions of visitor types have shifted over the years due to marketing strategies or change in preferences**

**2) Limited survey outreach which resulted in skewed survey responses**

**3) Both (1) and (2)**

We will discuss more about this in Steps 3 and 4 of the question.

--------------------------------------------------------------------------------

##### Time Of Day

###### Category 1: When do visitors usually spend their day at USS?

We can use the `day_preferred` column of the historical dataset to identify the most common day type that previous visitors visit USS.
"""

# Extract the day_preferred column
dfhistory_day = df_history['day_preferred']

# Define the desired order
order = ["Weekdays", "Weekends", "Public Holidays", "School Holidays", "Special Events"]

# Count occurrences and reindex to match the desired order
days = dfhistory_day.value_counts().reindex(order, fill_value=0)

# Create a bar plot
plt.figure(figsize=(10, 6))
ax = sns.barplot(x=days.index, y=days.values, order=order, color="pink")

# Add title and labels
plt.title("Number of Respondents Based on Preferred Days (Historical Data)")
plt.xlabel("Day Categories")
plt.ylabel("Number of Respondents")

# Rotate x-axis labels for better readability
plt.xticks(rotation=30, ha="right")

# Add grid lines for better readability
plt.grid(axis="y", linestyle="--", alpha=0.3)

# Add number labels on top of bars
for i, value in enumerate(days.values):
    ax.text(i, value + 1, str(value), ha='center', va='bottom', fontsize=10)

# Show the plot
plt.show()

"""Key Observations And Insights:

1) For the historical data, the majority of respondants chose Weekends as their preferred days, in contrast to Weekdays for the current data. There might be a shift in the visitor' preferences from Weekends to Weekdays.

2) The number of reviewers who prefer visiting USS during Special Events is the least among the other options, similar to the current dataset. However, contrary to the current dataset, the historical data shows much less visitors whose preference is on Speical Events.

3) The proportion of visitors who chose School Holidays as their preferred days to visit USS for the historic dataset is significantly lower compared to the current dataset.

--------------------------------------------------------------------------------

###### Category 2: What time of the day constitutes the highest demand?

We can use the `time_of_day` column of the historical dataset to identify the most common timings that previous visitors visit USS.
"""

# Extract the time_of_day column
dfhistory_time = df_history['time_of_day']

# Define the desired order of time categories
order = ["Early Morning (8am To 10am)", "Late Morning (10am To 12pm)",
         "Early Afternoon (12pm To 2pm)", "Late Afternoon (2pm To 4pm)",
         "Evening (4pm To 6pm)", "Night (6pm To 9pm)"]

# Count occurrences and reindex to match the desired order
timing = dfhistory_time.value_counts().reindex(order, fill_value=0)

# Create a bar plot
plt.figure(figsize=(10, 6))
ax = sns.barplot(x=timing.index, y=timing.values, order=order, color="orange")

# Add title and labels
plt.title("Number of Respondents Based on Preferred Timings (Historical Data)")
plt.xlabel("Time Categories")
plt.ylabel("Number of Respondents")

# Rotate x-axis labels for better readability
plt.xticks(rotation=30, ha="right")

# Add grid lines for better readability
plt.grid(axis="y", linestyle="--", alpha=0.3)

# Add number labels on top of bars
for i, value in enumerate(timing.values):
    ax.text(i, value + 1, str(value), ha='center', va='bottom', fontsize=10)

# Show the plot
plt.show()

"""Key Observations And Insights:

1) For the historical data, the majority of respondants chose Evening (4pm to 6pm) as their preferred timings to visit USS, in contrast to Late Afternoon (2pm to 4pm) for the current data. However, Late Afternoon (2pm to 4pm) still forms quite a significant proportion of visitors favorite timing for the historical data.  

2) The number of reviewers who prefer visiting USS during Early Morning (8am to 10am) and Night (6pm to 9pm) is the least among the other options, similar to the current dataset.  

3) The number of respondants still shows an increase from Early Morning (8am to 10am) to Late Afternoon (2pm to 4pm), similar to the current dataset.

--------------------------------------------------------------------------------

##### Special Events

We can use the `day_preferred` column of the historical dataset to identify how often previous visitors visit USS during special events as compared to other days.
"""

# Extract the day_preferred column
dfhistory_day = df_history['day_preferred']

# Define the desired order
order = ["Weekdays", "Weekends", "Public Holidays", "School Holidays", "Special Events"]

# Count occurrences and reindex to match the desired order
days = dfhistory_day.value_counts().reindex(order, fill_value=0)

# Create a bar plot
plt.figure(figsize=(10, 6))
ax = sns.barplot(x=days.index, y=days.values, order=order)

# Add title and labels
plt.title("Number of Reviewers Based on Preferred Days (Historical Data)")
plt.xlabel("Day Categories")
plt.ylabel("Number of Reviewers")

# Rotate x-axis labels for better readability
plt.xticks(rotation=30, ha="right")

# Add grid lines for better readability
plt.grid(axis="y", linestyle="--", alpha=0.3)

# Add number labels on top of bars
for i, value in enumerate(days.values):
    ax.text(i, value + 1, str(value), ha='center', va='bottom', fontsize=10)

# Show the plot
plt.show()

"""Similar to current survey visitor responses, the number of reviewers who prefer visiting USS during `Special Events` is the least among the other options. However, we observe that this difference between `Special Events` and other options is more significant in the historical data as compared to data obtained from recent survey responses. This might be due to the fact that there might be more advertising of these special events by USS in recent years that led to greater demand for USS during these events.

--------------------------------------------------------------------------------

##### Satisfaction Ratings

We will be using the `ratings` column as a metric to measure guest satisfaction of TripAdvisor reviewers in the past. To visualize the distribution of ratings, we will plot a bar chart.

**NOTE: The `rating` column is measured from 1 to 5, which is different from the scale from 1 to 10 in the satisfaction score for the current dataset. For example, We will assume that a rating of 4 in the historic dataset will translate to a rating of 8 in the current dataset.**
"""

# Create a bar plot
plt.figure(figsize=(10, 6))
ax = sns.countplot(x='rating', data=df_history)

# Add count labels on top of each bar
for p in ax.patches:
    ax.annotate(f'{int(p.get_height())}', (p.get_x() + p.get_width() / 2., p.get_height()),
                ha='center', va='center', xytext=(0, 10), textcoords='offset points')

# Add title and labels
plt.title('Distribution of Ratings')
plt.xlabel('Ratings')
plt.ylabel('Number of Reviewers')

# Add grid lines for better readability
plt.grid(axis='y', linestyle='--', alpha=0.3)

# Show the plot
plt.show()

"""Key Observations And Insights:

1) As seen from the bar chart above, over 83% of reviewers gave USS a rating of 4 and 5 on TripAdvisor, suggesting that they were generally satisfied with their experience. A minority (5.4%) expressed their dissatisfaction by giving ratings of 1 and 2.

2) The ratings of USS historically is generally higher compared to the satisfaction ratings of USS currently (the mode rating for historic data is 5 but the mode rating for the current USS is 7/10, which is only between 3 and 4 when translated to a scale of 5). This means that overall satisfaction of USS fell in the recent years.

++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

#### Step 3: Compare The Visitor Demographics + Identify Trends And Majority Classes

For effective comparisons of visitor demographics, we can make use of heatmaps for every demographic section. We will be comparing proportions in the form of percentages (in 1 decimal place for all heatmapsfor consistency) instead of counts as the number of survey responses in the historic data far exceeds the number of survey responses in the current data (almost 15000 vs 500).

The sections that we will be comparing are:

**1.   Age Of Visitors**

**2.   Gender Of Visitors**

**3.   Nationality Of Visitors**

**4.   Visitor Type**

**5.   Preferred Days**

**6.   Preferred Timing**

**7.   Satisfaction Ratings**

###### Age Of Visitors:
"""

# Define age order
order = ["Below 12 Years Old", "13 To 20 Years Old", "21 To 34 Years Old",
         "35 To 49 Years Old", "50 To 64 Years Old", "65 Years Old And Above"]

# Compute proportions for current data
df_agerange = df['q2_1']
current_counts = df_agerange.value_counts().reindex(order, fill_value=0)
current_proportions = (current_counts / current_counts.sum() * 100).round(1)

# Compute proportions for historical data
dfhistory_agerange = df_history['age_range']
historic_counts = dfhistory_agerange.value_counts().reindex(order, fill_value=0)
historic_proportions = (historic_counts / historic_counts.sum() * 100).round(1)

# Combine into a DataFrame
heatmap_data = pd.DataFrame({'Current Data': current_proportions, 'Historical Data': historic_proportions})
annot_data = heatmap_data.astype(str) + "%"

# Create the heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(heatmap_data, annot=annot_data, cmap="Reds", fmt="", linewidths=0.5)
plt.title("Age Group Proportions: Current vs. Historical Data")
plt.show()

"""--------------------------------------------------------------------------------

###### Gender Of Visitors:
"""

# Compute gender proportions for current dataset
df_gender = df['q2_2']
current_counts = df_gender.value_counts()
current_proportions = (current_counts / current_counts.sum() * 100).round(1)

# Compute gender proportions for historical dataset
dfhistory_gender = df_history['gender']
historic_counts = dfhistory_gender.value_counts()
historic_proportions = (historic_counts / historic_counts.sum() * 100).round(1)

# Combine into a DataFrame
heatmap_data = pd.DataFrame({'Current Data': current_proportions, 'Historical Data': historic_proportions})
annot_data = heatmap_data.astype(str) + "%"

# Create the heatmap
plt.figure(figsize=(10, 6))
sns.heatmap(heatmap_data, annot=annot_data, cmap="Greens", fmt="", linewidths=0.5)
plt.title("Gender Proportions: Current vs. Historical Data")
plt.show()

"""--------------------------------------------------------------------------------

###### Nationality Of Visitors:
"""

# Compute nationality proportions for current dataset
df_nationality = df['q3']
current_counts = df_nationality.value_counts()
current_proportions = (current_counts / current_counts.sum() * 100).round(1)

# Compute nationality proportions for historical dataset
dfhistory_nationality = df_history['nationality']
historic_counts = dfhistory_nationality.value_counts()
historic_proportions = (historic_counts / historic_counts.sum() * 100).round(1)

# Combine into a DataFrame
heatmap_data = pd.DataFrame({'Current Data': current_proportions, 'Historical Data': historic_proportions})
annot_data = heatmap_data.astype(str) + "%"

# Create the heatmap
plt.figure(figsize=(10, 6))
sns.heatmap(heatmap_data, annot=annot_data, cmap="Blues", fmt="", linewidths=0.5)
plt.title("Nationality Proportions: Current vs. Historical Data")
plt.show()

"""--------------------------------------------------------------------------------

###### Visitor Type:
"""

# Standardize visitor type labels to match both datasets
order = ['Solo Traveller', 'Visiting With Friends', 'Family With Young Children',
         'Family With Teenagers', 'Family With Elderly']

# Replace 'Families' with 'Family' in historical data for consistency
df_history['visitor_type'] = df_history['visitor_type'].replace({
    'Families With Young Children': 'Family With Young Children',
    'Families With Teenagers': 'Family With Teenagers',
    'Families With Elderly': 'Family With Elderly'
})

# Compute visitor type proportions for current dataset
current_counts = df['q1'].value_counts().reindex(order, fill_value=0)
current_proportions = (current_counts / current_counts.sum() * 100).round(1)

# Compute visitor type proportions for historical dataset
historic_counts = df_history['visitor_type'].value_counts().reindex(order, fill_value=0)
historic_proportions = (historic_counts / historic_counts.sum() * 100).round(1)

# Combine into a DataFrame
heatmap_data = pd.DataFrame({'Current Data': current_proportions, 'Historical Data': historic_proportions})
annot_data = heatmap_data.astype(str) + "%"

# Create the heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(heatmap_data, annot=annot_data, cmap="Purples", fmt="", linewidths=0.5)
plt.title("Visitor Type Proportions: Current vs. Historical Data")
plt.show()

"""--------------------------------------------------------------------------------

###### Preferred Days:
"""

# Code From Just Now (Repeated)
q10_column = df['q10']
q10_column = q10_column.replace(r'Special Events \(.*\)', 'Special Events', regex=True)
split_q10 = q10_column.str.split(',', expand=True)
categories = ['Weekdays', 'Weekends', 'Public Holidays', 'School Holidays',
              'Special Events', 'When I feel like it', '1 day in 25 years']
one_hot_df = pd.DataFrame(0, index=df.index, columns=categories)
for category in categories:
    one_hot_df[category] = split_q10.apply(lambda row: 1 if category in row.values else 0, axis=1)
count_ones = one_hot_df.sum()
count_ones = count_ones.drop(['When I feel like it', '1 day in 25 years'])

# Normalize the count to get proportions (convert to percentage)
current_proportions = (count_ones / count_ones.sum() * 100).round(1)

# Compute preferred day proportions for historical dataset
dfhistory_day = df_history['day_preferred']
days = dfhistory_day.value_counts().reindex(categories[:5], fill_value=0)

# Normalize the historical count to get proportions (convert to percentage)
historic_proportions = (days / days.sum() * 100).round(1)

# Combine into a DataFrame
heatmap_data = pd.DataFrame({'Current Data': current_proportions, 'Historical Data': historic_proportions})
annot_data = heatmap_data.astype(str) + "%"

# Create the heatmap
plt.figure(figsize=(9, 6))
sns.heatmap(heatmap_data, annot=annot_data, cmap="Oranges", fmt="", linewidths=0.5)
plt.title("Preferred Day Proportions: Current vs. Historical Data")
plt.show()

"""--------------------------------------------------------------------------------

###### Preferred Timing:
"""

# Code From Just Now (Repeated)
popular_time_range = df[['q14_1', 'q14_2', 'q14_3', 'q14_4', 'q14_5', 'q14_6', 'q14_7', 'q14_8']]
flattened_time_range = popular_time_range.values.flatten()
split_time_range = [item.strip() for sublist in flattened_time_range for item in str(sublist).split(',')]
time_range_series = pd.Series(split_time_range)
time_slot_counts = time_range_series.value_counts()
time_slot_counts = time_slot_counts[~time_slot_counts.index.isin(['', 'Lunch (11am to 2pm)', 'i Do Not Visit'])]
time_slot_counts = time_slot_counts.rename(index = {'i Do Not Visit': 'I Do Not Visit'})
time_slot_counts['I Do Not Visit'] += 3
time_slot_counts = time_slot_counts.drop(['I Do Not Visit'])
order = ["Early Morning (8am to 10am)", "Late Morning (10am to 12pm)",
         "Early Afternoon (12pm to 2pm)", "Late Afternoon (2pm to 4pm)",
         "Evening (4pm to 6pm)", "Night (6pm to 9pm)"]
time_period_counts = time_slot_counts.reindex(order, fill_value=0)
current_proportions = (time_period_counts / time_period_counts.sum() * 100).round(1)
dfhistory_time = df_history['time_of_day']
dfhistory_time = dfhistory_time.replace({
    "Early Morning (8am To 10am)": "Early Morning (8am to 10am)",
    "Late Morning (10am To 12pm)": "Late Morning (10am to 12pm)",
    "Early Afternoon (12pm To 2pm)": "Early Afternoon (12pm to 2pm)",
    "Late Afternoon (2pm To 4pm)": "Late Afternoon (2pm to 4pm)",
    "Evening (4pm To 6pm)": "Evening (4pm to 6pm)",
    "Night (6pm To 9pm)": "Night (6pm to 9pm)"
})
timing = dfhistory_time.value_counts().reindex(order, fill_value=0)

# Normalize the historical count to get proportions (convert to percentage)
historic_proportions = (timing / timing.sum() * 100).round(1)

# Combine into a DataFrame
heatmap_data = pd.DataFrame({'Current Data': current_proportions, 'Historical Data': historic_proportions})
annot_data = heatmap_data.astype(str) + "%"

# Create the heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(heatmap_data, annot=annot_data, cmap="Greys", fmt="", linewidths=0.5)
plt.title("Preferred Time Slot Proportions: Current vs. Historical Data")
plt.show()

"""++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

#### Step 4: Implement Effective Strategies To Tailor To The Identified Groups
"""